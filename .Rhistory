labs(size = "Round") +
theme_classic()
fig1
table2.1 <- df_narrow %>%
filter(treatment == "individuals") %>%
group_by(round, treatment) %>%
summarise(y = mean(investment))
table2.2 <- df_narrow %>%
filter(treatment == "pay-comm") %>%
group_by(round, treatment) %>%
summarise(y = mean(investment))
table2.3 <- df_narrow %>%
filter(treatment == "message") %>%
group_by(round, treatment) %>%
summarise(y = mean(investment))
table2 <- rbind(table2.1, table2.2)
table2 <- rbind(table2, table2.3)
fig2 <- ggplot(table2, aes(round, y, group = treatment)) + geom_line(color = "grey") + geom_point(alpha = 0.75, aes(shape = treatment))
fig2
pic2 <- df_narrow %>%
select(treatment, round, investment) %>%
filter(treatment == c("individuals", "pay-comm", "message")) %>%
group_by(treatment, round) %>%
summarise(y = mean(investment, na.rm = TRUE)) %>%
ggplot(., aes(round, y)) +
geom_line(aes(group = treatment), color = "grey") +
geom_point(alpha=0.75, aes(shape = treatment)) +
labs(size = "Round") +
theme_classic()
pic2
fig3 <- df_narrow %>%
select(treatment, round, investment) %>%
filter(treatment == c("individuals", "mixed")) %>%
group_by(round, treatment) %>%
summarise(y = mean(investment)) %>%
ggplot(., aes(round, y)) +
geom_line(aes(group = treatment), color = "grey") +
geom_point(alpha=0.75, aes(shape = treatment)) +
labs(size = "Round") +
theme_classic()
fig3
rm(table1, table2.1, table2.2, table2.3, table2, table3)
plot_grid(fig1, fig2, fig3,
labels = c('a', 'b', 'c'),
nrow = 1)
df_team_avg <- df_narrow %>%
group_by(treatment, uniqueteam) %>%
summarise(mean(investment))
# should be get 99 rows
df_narrow %>%
group_by(uniqueteam) %>%
summarise(mean(investment))
ppl <- df_team_avg$`mean(investment)`[which(df_team_avg == "individuals")]
team <- df_team_avg$`mean(investment)`[which(df_team_avg == "teams")]
wilcox.test(ppl, team, var.equal=F, paired = F)
pay <- df_team_avg$`mean(investment)`[which(df_team_avg == "pay-comm")]
mes <- df_team_avg$`mean(investment)`[which(df_team_avg == "message")]
wilcox.test(ppl, pay, var.equal = F, paired = F)
wilcox.test(pay, mes, var.equal = F, paired = F)   # 0.06903
wilcox.test(team, mes, var.equal = F, paired = F)
wilcox.test(team, pay, var.equal = F, paired = F)
#df_narrow <- cbind(df_narrow, dummy(df_narrow$treatment, sep = "_"))
m <- lm(investment ~ treatment, data = df_narrow)
summary(m)
vcov_subjectid <- sandwich::vcovCL(m, cluster = df_narrow$uniquesubject)
lmtest::coeftest(m, vcov_subjectid)
pic2 <- df_narrow %>%
select(treatment, round, investment) %>%
filter(treatment == c("individuals" or "pay-comm" or "message")) %>%
fig2
fig2
knitr::opts_chunk$set(echo = TRUE)
# a.
tute1 <- read.csv("/Users/apple/Desktop/bc_f19_econ/Forecasting/Probset1_files/tute1.csv", header = TRUE)
# bayesian updating -------------------------------------------------------
# x|theta ~ Binomial(n,theta)
# theta ~ Beta(a,b)
## the beta distribution:
curve(dbeta(x,1,1),ylim=c(0,5),ylab="Beta(a,b)")
for(i in 2:20) curve(dbeta(x,i,i), add=T, col=i)
# conjugate posterior: theta|x ~ Beta(x+a, n-x+b)
sim_learning <- function(a=1,b=1,n=100,n_reps=100, q=1,true_p = 0.25,bias=F,learning=T,title=NULL) {
beta_mean <- function() return((a) / (a + b))
pr <- beta_mean()
data <- c(pr)
for(i in 1:n_reps) {
x <- rbinom(1, 1, true_p)
if(bias){
if(x==1) ps <- (1-q)*(beta_mean()) + q*pr
else ps <- q*(beta_mean()) + (1-q)*pr
} else {
ps <- q*beta_mean() + (1-q)*pr
}
data <- append(data, ps)
if(learning){
if(x == 1){ # a + x
a <- a + 1
}
else{ # a + (n-x)
b <- b + 1
}
}
}
plot(data, type = "l", ylim = c(0,1), xlab = "Flip", ylab = "P(Heads)", main=title)
abline(h=true_p, col="red")
return(data)
}
# no learning
sim_learning(n_reps = 10000, learning = F)
# bayesian updating -------------------------------------------------------
# x|theta ~ Binomial(n,theta)
# theta ~ Beta(a,b)
## the beta distribution:
curve(dbeta(x,1,1),ylim=c(0,5),ylab="Beta(a,b)")
for(i in 2:20) curve(dbeta(x,i,i), add=T, col=i)
# conjugate posterior: theta|x ~ Beta(x+a, n-x+b)
sim_learning <- function(a=1,b=1,n=100,n_reps=100, q=1,true_p = 0.25,bias=F,learning=T,title=NULL) {
beta_mean <- function() return((a) / (a + b))
pr <- beta_mean()
data <- c(pr)
for(i in 1:n_reps) {
x <- rbinom(1, 1, true_p)
# random binomial curve,
# rbinom(1,1,0.5)
if(bias){
if(x==1) ps <- (1-q)*(beta_mean()) + q*pr
else ps <- q*(beta_mean()) + (1-q)*pr
} else {
ps <- q*beta_mean() + (1-q)*pr
}
data <- append(data, ps)
if(learning){
if(x == 1){ # a + x
a <- a + 1
}
else{ # a + (n-x)
b <- b + 1
}
}
}
plot(data, type = "l", ylim = c(0,1), xlab = "Flip", ylab = "P(Heads)", main=title)
abline(h=true_p, col="red")
return(data)
}
# no learning
sim_learning(n_reps = 10000, learning = F)
# learning
par(mfrow=c(2,2))
sim_learning(n_reps=10, title="N=10")
sim_learning(n_reps=10^2, title="N=10^2")
sim_learning(n_reps=10^3, title="N=10^3")
sim_learning(n_reps=10^4, title="N=10^4")
dev.off()
# confirmation bias (sort of...)
sim_learning(n_reps = 1000, learning = T, bias = T, q=1)
sim_learning(n_reps = 1000, learning = T, q=1)
sim_learning(n_reps = 1000, learning = T, bias = T, q=0.25)
sim_learning(n_reps = 1000, learning = T, q=0.25)
sim_learning(n_reps = 1000, learning = T, q=1)
sim_learning(n_reps = 1000, learning = T, q=0.25)
# attempt at a model of confirmation bias
## sort of works - but needs improvement
sim_bias <- function(n=100,true_p = 0.25, samp_size=4, alpha = 0.05, bias=F,title=NULL) {
a <- b <- 1
beta_mean <- function() return((a) / (a + b))
pr <- beta_mean()
posteriors <- c(pr)
data <- c()
S <- c()
for(i in 1:n) {
x <- rbinom(samp_size, 1, true_p)
if(bias){
test <- binom.test(sum(x),length(x),pr)
if(test$p.value >= alpha) {
a <- a + sum(x) # a + x
b <- b + (length(x) - sum(x)) # b + (n-x)
} else {
s <- 0
new_pvalue <- 0
while(new_pvalue<alpha){
new_x <- rbinom(samp_size, 1, true_p)
new_test <- binom.test(sum(new_x), length(new_x), pr)
new_pvalue <- new_test$p.value
s <- s+1
}
S <- append(S, s)
a <- a + sum(new_x) # a + x
b <- b + (length(new_x) - sum(new_x)) # b + (n-x)
}
ps <- beta_mean()
} else {
a <- a + sum(x) # a + x
b <- b + (length(x) - sum(x)) # b + (n-x)
ps <- beta_mean()
}
posteriors <- append(posteriors, ps)
}
par(mfrow=c(1,2))
plot(posteriors, type = "l", col="black", ylim = c(0,1), xlab = "Sample", ylab = "P(Fair)", main=title)
abline(h=true_p, col="red")
hist(S,col="gray", main="", xlab="Resampling")
}
sim_bias(bias=T, samp_size = 52)
S <- append(S, s)
# attempt at a model of confirmation bias
## sort of works - but needs improvement
sim_bias <- function(n=100,true_p = 0.25, samp_size=4, alpha = 0.05, bias=F,title=NULL) {
a <- b <- 1
beta_mean <- function() return((a) / (a + b))
pr <- beta_mean()
posteriors <- c(pr)
data <- c()
S <- c()
for(i in 1:n) {
x <- rbinom(samp_size, 1, true_p)
if(bias){
test <- binom.test(sum(x),length(x),pr)
if(test$p.value >= alpha) {
a <- a + sum(x) # a + x
b <- b + (length(x) - sum(x)) # b + (n-x)
} else {
s <- 0
new_pvalue <- 0
while(new_pvalue<alpha){
new_x <- rbinom(samp_size, 1, true_p)
new_test <- binom.test(sum(new_x), length(new_x), pr)
new_pvalue <- new_test$p.value
s <- s+1
}
S <- append(S, s)
a <- a + sum(new_x) # a + x
b <- b + (length(new_x) - sum(new_x)) # b + (n-x)
}
ps <- beta_mean()
} else {
a <- a + sum(x) # a + x
b <- b + (length(x) - sum(x)) # b + (n-x)
ps <- beta_mean()
}
posteriors <- append(posteriors, ps)
}
par(mfrow=c(1,2))
plot(posteriors, type = "l", col="black", ylim = c(0,1), xlab = "Sample", ylab = "P(Fair)", main=title)
abline(h=true_p, col="red")
hist(S,col="gray", main="", xlab="Resampling")
}
sim_bias(bias=T, samp_size = 52)
sim_bias(bias = T, samp_size = 40)
sim_bias(bias=T, samp_size = 52)
sim_bias(bias = T, samp_size = 40)
sim_bias(bias=T, samp_size = 52)
sim_bias(bias = T, samp_size = 40)
sim_bias(bias=T, samp_size = 52)
sim_bias(bias = T, samp_size = 40)
hsales
hsale
library(fpp2)
hsales
lambda <- BoxCox.lambda(usnetelec)
autoplot(BoxCox(usnetelec, lambda))
lambda
rm(list = ls()) # Clear environment
library(tidyverse)
library(tidyverse)
library(cowplot)
#install.packages("lfe")
library(lfe)
install.packages("lfe")
library(lfe)
library(stargazer)
curve(dbeta(x,1,1),ylim=c(0,5),ylab="Beta(a,b)")
for(i in 2:20) curve(dbeta(x,i,i), add=T, col=i)
curve(dbeta(x,1,1),ylim=c(0,5),ylab="Beta(a,b)")
curve(dbeta(x,1,1),ylim=c(0,50)
curve(dbeta(x,1,1),ylim=c(0,50))
curve(dbeta(x,1,1),ylim=c(0,50))
curve(dbeta(x,1,1),ylim=c(0,10))
curve(dbeta(x,1,4),ylim=c(0,10))
?dbeta
dailycorr <- read.csv("dailycorrs.csv")
View(dailycorr)
View(dailycorr)
p1 <- ggplot(dailycorr, aes(x=logv, y=logf)) +
geom_point(size=2, shape=23) +
geom_smooth(method="auto", se=TRUE, fullrange=FALSE, level=0.95) +
labs(title = "Correlation Test of Delivery Companies", x = "log of Veloblitz", y = "log of Flash") +
theme_classic()
p1
p1 <- ggplot(dailycorr, aes(x=logv, y=logf)) +
geom_point(size=2, shape=23) +
geom_smooth(method="auto", se=FALSE, fullrange=FALSE, level=0.95) +
labs(title = "Correlation Test of Delivery Companies", x = "log of Veloblitz", y = "log of Flash") +
theme_classic()
p1
p1 <- ggplot(dailycorr, aes(x=logv, y=logf)) +
geom_point(size=2, shape=23) +
geom_smooth(method=lm, se=FALSE, fullrange=FALSE, level=0.95) +
labs(title = "Correlation Test of Delivery Companies", x = "log of Veloblitz", y = "log of Flash") +
theme_classic()
p1
View(dailycorr)
p2 <- ggplot(dailycorr) + geom_density()
p2
p2 <- ggplot(dailycorr) + geom_density()
p2
# should we e^* back to revenues
p2 <- ggplot(dailycorr, aes(x=logv, fill=sex)) +
geom_density(alpha=0.4)
p2
# should we e^* back to revenues
p2 <- ggplot(dailycorr, aes(x=logv, fill=logv)) +
geom_density(alpha=0.4)
p2
# should we e^* back to revenues
p2 <- ggplot(dailycorr, aes(x=logv, fill=logf)) +
geom_density(alpha=0.4)
p2
# should we e^* back to revenues
p2 <- ggplot(dailycorr, aes(x=c(logv, logf), fill=logf)) +
geom_density(alpha=0.4)
p2
# should we e^* back to revenues
p2 <- ggplot(dailycorr, aes(x=logf, x = logv, fill=logf)) +
geom_density(alpha=0.4)
# should we e^* back to revenues
p2 <- ggplot(dailycorr, aes(x=logf, y = logv, fill=logf)) +
geom_density(alpha=0.4)
p2
View(dailycorr)
totrev_fe <- read_csv("tables1to4.csv")
View(totrev_fe)
View(totrev_fe)
df <- read_csv("tables1to4.csv")
df <- read_csv("tables1to4.csv")
mean_rev <- df %>% mean(totrev)
df %>% mutate(totrev_fe = totrev - mean_rev)
View(df)
rm(list = ls()) # Clear environment
library(tidyverse)
library(cowplot)
#install.packages("lfe")
library(lfe)
library(stargazer)
df <- read_csv("tables1to4.csv")
mean_rev <- df %>% mean(totrev)
View(df)
is.na(df$totrev)
mean(df$totrev)
df %>% mean(totrev)
df %>% mean(., totrev)
mean_rev <- mean(df$totrev)
df %>% mutate(totrev_fe = totrev - mean_rev)
df <- df %>% mutate(totrev_fe = totrev - mean_rev)
e_t <- function(t) {
e <- w_t/1
return(e)
}
curve(e_t, 0, 10)
e_t <- function(w_t) {
e <- w_t/1
return(e)
}
curve(e_t, 0, 10)
View(df)
e_t <- function(w_t) {
u <- ifelse(u >= 3/w_t, w_t, 2*w_t)
return(u)
}
curve(e_t, 0, 10)
e_t <- function(w_t) {
e <- ifelse(u >= 3/w_t, w_t, 2*w_t)
return(e)
}
curve(e_t, 0, 10)
rm(list = ls()) # Clear environment
library(tidyverse)
library(cowplot)
#install.packages("lfe")
library(lfe)
library(stargazer)
library(reshape2)
e_t <- function(w) {
e <- ifelse(w < sqrt(1*3/2), 2*3*w, ifelse(w > sqrt(1*3/1), w, 3/w))
return(e)
}
curve(e_t, 0, 10)
df <- read_csv("tables1to4.csv")
```{r, warning=FALSE, message=FALSE}
df <- read_csv("tables1to4.csv")
df <- df %>%
group_by(fahrer) %>%
mutate(totrev_fe = totrev - mean(totrev))
rm(list = ls()) # Clear environment
library(tidyverse)
library(cowplot)
#install.packages("lfe")
library(lfe)
library(stargazer)
library(reshape2)
df %>%
summarise(mean)
df %>%
summarise(mean(totrev_fe))
df <- read_csv("tables1to4.csv")
df <- df %>%
group_by(fahrer) %>%
mutate(totrev_fe = totrev - mean(totrev))
df %>%
summarise(mean(totrev_fe))
View(df)
length(df$totrev_fe)
n(df$totrev_fe)
n(df)
summarise(mean, sd)
df_avg_revenue <- df %>%
group_by(fahrer) %>%
mutate(sd = sd(totrev_fe)) %>%
mutate(sd/sqrt(length(totrev_fe))) %>%
summarise(mean, sd)
df_avg_revenue <- df %>%
group_by(fahrer) %>%
mutate(sd = sd(totrev_fe)) %>%
mutate(sd/sqrt(length(totrev_fe))) %>%
summarise(mean(totrev_fe), sd(totrev_fe))
View(df_avg_revenue)
df_avg_revenue <- df %>%
group_by(fahrer) %>%
mutate(sd = sd(totrev_fe)) %>%
#mutate(sd/sqrt(length(totrev_fe))) %>%
summarise(avg_rev = mean(totrev_fe), se_rev = sd(totrev_fe)/sqrt(length(totrev_fe)))
View(df_avg_revenue)
#group_by() %>%
#summarize(sum_trade = sum(trade),mean_trade = mean(trade), distance_to_mangola = unique(distance_to_mangola))%>%
ggplot(., aes(distance_to_mangola,mean_trade,size=sum_trade,label=campname)) +
geom_point(position = posiion_dodge(width = 0.5), size = 4, color="tomato") +
geom_errorbar(aes(x = block, ymin = , ymax), wid = .1, position = position_dodge(width = 0.5))
df_avg_revenue %>%
na.omit(odd) %>%
#group_by() %>%
#summarize(sum_trade = sum(trade),mean_trade = mean(trade), distance_to_mangola = unique(distance_to_mangola))%>%
ggplot(., aes(distance_to_mangola,mean_trade,size=sum_trade,label=campname)) +
geom_point(position = posiion_dodge(width = 0.5), size = 4, color="tomato") +
geom_errorbar(aes(x = block, ymin = , ymax), wid = .1, position = position_dodge(width = 0.5))
df_avg_revenue %>%
na.omit(odd) %>%
#group_by() %>%
#summarize(sum_trade = sum(trade),mean_trade = mean(trade), distance_to_mangola = unique(distance_to_mangola))%>%
ggplot(., aes(distance_to_mangola,mean_trade,size=sum_trade,label=campname)) +
geom_point(position = posiion_dodge(width = 0.5), size = 4, color="tomato") +
geom_errorbar(aes(x = block, ymin = , ymax), wid = .1, position = position_dodge(width = 0.5)) +
geom_text(aes(label=campname),hjust=0, vjust=0,size=3) +
labs(size = "") +
theme_classic()
rm(list = ls()) # Clear environment
library(tidyverse)
library(cowplot)
#install.packages("lfe")
library(lfe)
library(stargazer)
library(reshape2)
e_t <- function(w_t) {
e <- w_t/1
return(e)
}
curve(e_t, 0, 10)
e_t <- function(w) {
e <- ifelse(w < sqrt(1*3/2), 2*3*w, ifelse(w > sqrt(1*3/1), w, 3/w))
return(e)
}
curve(e_t, 0, 10)
dailycorr <- read.csv("dailycorrs.csv")
p1 <- ggplot(dailycorr, aes(x=logv, y=logf)) +
geom_point(size=2, shape=23) +
geom_smooth(method=lm, se=FALSE, fullrange=FALSE, level=0.95) +
labs(title = "Correlation Test of Delivery Companies", x = "log of Veloblitz", y = "log of Flash") +
theme_classic()
# should we $e^*$ back to revenues; create a new table - Doesn't matter with the shape
rev_delivery <- melt(exp(dailycorr))
p2 <- ggplot(rev_delivery, aes(x = value, fill = variable)) +
geom_density(alpha=0.4) +
labs(title = "Kernel density estimates",
x = "Revenues $", y = "Density") +
theme_classic()
# Alternatively,
dailycorr %>%
gather() %>%
ggplot(., aes(value, fill = key)) +
geom_density(alpha = 0.5) +
labs(title = "Kernel density estimates",
x = "Density", y = "Density") +
theme_classic()
plot_grid(p1, p2, labels = c('14', '15'),
nrow = 1)
df <- read_csv("tables1to4.csv")
df <- df %>%
group_by(fahrer) %>%
mutate(totrev_fe = totrev - mean(totrev))
df_avg_revenue <- df %>%
group_by(fahrer) %>%
mutate(sd = sd(totrev_fe)) %>%
#mutate(sd/sqrt(length(totrev_fe))) %>%
summarise(avg_rev = mean(totrev_fe), se_rev = sd(totrev_fe)/sqrt(length(totrev_fe)))
df_avg_revenue %>%
na.omit(odd) %>%
#group_by() %>%
#summarize(sum_trade = sum(trade),mean_trade = mean(trade), distance_to_mangola = unique(distance_to_mangola))%>%
ggplot(., aes(distance_to_mangola,mean_trade,size=sum_trade,label=campname)) +
geom_point(position = posiion_dodge(width = 0.5), size = 4, color="tomato") +
geom_errorbar(aes(x = block, ymin = , ymax), wid = .1, position = position_dodge(width = 0.5)) +
geom_text(aes(label=campname),hjust=0, vjust=0,size=3) +
labs(size = "") +
theme_classic()
