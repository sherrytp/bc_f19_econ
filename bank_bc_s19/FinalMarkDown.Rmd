---
title: "Final Project - Sentiment Analysis"
date: "May 11, 2018"
output: html_document
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
library(stringr)
library(plyr)
library(data.table)
library(readr)
library(ggplot2)
library(tm)
library(NLP)
library(data.table)
library(ModelMetrics)
library(e1071)
library(caret)
library(randomForest)
library(scales); library(grid); library(RColorBrewer)
```


```{r, include = FALSE}
setwd("/Users/namsan/Desktop/Spring\ 2018/Big\ Data/projFld/RawData")
tr <- data.table(read.csv("train.tsv",sep='\t', stringsAsFactors = F))
```
  
```{r, include = FALSE}
splitCut <- 0.7
set.seed(123)
trows <- nrow(tr)
tr[, tmp_rnd := runif(trows)]
trainRaw <- tr[tmp_rnd <= splitCut][, tmp_rnd := NULL]
test <- tr[tmp_rnd > splitCut][, tmp_rnd := NULL]
```


# Data Exploration

```{r}
str(trainRaw)
summary(trainRaw)
table(trainRaw$Sentiment)
summary(trainRaw$SentenceId)

train <- copy(trainRaw)

train <- data.table(train)
```

# Prepare data - get the whole reviews from data
```{r}
setkeyv(train, c("SentenceId", "PhraseId"))

train <- train[, sent_start:=min(PhraseId), by=.(SentenceId)]

senTrain <- train[ sent_start == PhraseId][, sent_start := NULL]

setkeyv(test, c("SentenceId", "PhraseId"))

test <- test[, sent_start:=min(PhraseId), by=.(SentenceId)]

senTest <- test[ sent_start == PhraseId][, sent_start := NULL]
```

# Text mining - Using tm package

```{r}
senTrain.tm<- copy(senTrain)
setnames(senTrain.tm, "SentenceId", "doc_id")
setnames(senTrain.tm, "Phrase", "text")

reviewCorpus <- Corpus(DataframeSource(senTrain.tm))
inspect(reviewCorpus[[1]])

reviewCorpus <- tm_map(reviewCorpus, content_transformer(tolower))
```

# What are stopwords?

```{r}
stopwords("english")
```


# Exclude some stopwords

```{r}
exceptions<- c('but','only','too','not','nor','most','again','because')
my_stopwords <- setdiff(stopwords("english"), exceptions)
```

# Eliminate punctuation, white space, stopWords, numbers
```{r}
skipWords <- function(x) removeWords(x, my_stopwords)
funcs <- list(removePunctuation, removeNumbers, stripWhitespace, skipWords)
cleanText <- tm_map(reviewCorpus, FUN = tm_reduce, tmFuns = funcs)
inspect(cleanText[[1]])
```


# Finding most frequent words with length from 3-20 characters

```{r}
freqMatrix <- TermDocumentMatrix(cleanText, control = list(wordLengths = c(3,20)))
inspect(freqMatrix)
```

# Investigate rrb and lrb 

```{r}
senTrainsubset <- senTrain[ grep("lrb", senTrain$Phrase), ]
```

```{r, include = FALSE}
sentence <- "the sensational true-crime hell-jaunt purists might like and more experimental in its storytelling -lrb- though no less horrifying for it -rrb- ."
```
```{r}
sentence
```

# Pick only 200 most frequent words

```{r, include = FALSE}
freqMatrix1 <- as.matrix(freqMatrix)
freqMatrix.sort <- sort(rowSums(freqMatrix1), decreasing=TRUE)
words.200 <- head(names(freqMatrix.sort), 202)
```
```{r}
words.200
```


# Remove ,()[].; from Phrase and make the text to lower case 

```{r}
senTrain$Phrase <- tolower(senTrain$Phrase)
senWords <- senTrain[, strsplit(Phrase,' ', fixed = T), by=.(SentenceId, Sentiment)]

setnames(senWords, "V1", "word")

wordBySent <- senWords[, (cnt=.N), by=.(word, Sentiment)]

setnames(wordBySent, "V1", "frequency")
```

# Create density variable

```{r}
wordBySent1 <- copy(wordBySent)
wordBySent1$Sentiment <- as.factor(wordBySent1$Sentiment)
wordBySent1 <- merge(wordBySent1, data.frame(table(Sentiment = wordBySent1$Sentiment)), by = c("Sentiment"))
setnames(wordBySent1, "Freq", "class.width")

wordBySent1 <- wordBySent1[, density := (frequency/class.width)]
```

# Subset the whole density table with only the "good" frequentwords from tm package

```{r}
densitytable.long <- wordBySent1[wordBySent1$word %chin% words.200]

densitytable <- dcast(densitytable.long, word ~ Sentiment, value.var = "density")
setnames(densitytable, c("0", "1", "2", "3", "4"), c("SN", "N", "NE", "P", "SP"))
```

# Pick the sentiment with the highest density for each words 

```{r, include=FALSE}
bestSent <- colnames(densitytable)[apply(densitytable,1,which.max)]
```

```{r}
densitytable <- cbind(densitytable, bestSent)
```
```{r}
densitytable$bestSent <- as.numeric(factor(densitytable$bestSent, 
                 levels = c("SN", "N", "NE", "P", "SP"), 
                 ordered = TRUE))
```

# Convert sentiment category 

```{r}
new <- densitytable[get("bestSent") == 1, eval("bestSent") := -5]
new <- new[get("bestSent") == 2, eval("bestSent") := -1]
new <- new[get("bestSent") == 3, eval("bestSent") := 0]
new <- new[get("bestSent") == 4, eval("bestSent") := 1]
```

```{r}
table(densitytable$bestSent)
```

# Visualization 30 most frequent words
```{r, include = FALSE}
fte_theme <- function() {
  
  # Generate the colors for the chart procedurally with RColorBrewer
  
  palette <- brewer.pal("Greys", n=9)
  color.background = palette[2]
  color.grid.major = palette[3]
  color.axis.text = palette[6]
  color.axis.title = palette[7]
  color.title = palette[9]
  
  # Begin construction of chart
  
  theme_bw(base_size=9) +
    
    # Set the entire chart region to a light gray color
    
    theme(panel.background=element_rect(fill=color.background, color=color.background)) +
    theme(plot.background=element_rect(fill=color.background, color=color.background)) +
    theme(panel.border=element_rect(color=color.background)) +
    
    # Format the grid
    
    theme(panel.grid.major=element_line(color=color.grid.major,size=.25)) +
    theme(panel.grid.minor=element_blank()) +
    theme(axis.ticks=element_blank()) +
    
    # Format the legend, but hide by default
    
    theme(legend.position="none") +
    theme(legend.background = element_rect(fill=color.background)) +
    theme(legend.text = element_text(size=7,color=color.axis.title)) +
    
    # Set title and axis labels, and format these and tick marks
    
    theme(plot.title=element_text(color=color.title, size=10, vjust=1.25)) +
    theme(axis.text.x=element_text(size=7,color=color.axis.text)) +
    theme(axis.text.y=element_text(size=7,color=color.axis.text)) +
    theme(axis.title.x=element_text(size=8,color=color.axis.title, vjust=0)) +
    theme(axis.title.y=element_text(size=8,color=color.axis.title, vjust=1.25)) +
    
    # Plot margins
    
    theme(plot.margin = unit(c(0.35, 0.2, 0.3, 0.35), "cm"))
}


# Average Star Rating by Category
wordfreq.plot <- aggregate(frequency ~ word, densitytable.long, sum)
wordfreq.plot <- wordfreq.plot[with(wordfreq.plot,order(-frequency)), ]
wordfreq.plot <- head(wordfreq.plot,30)

```

```{r}
ggplot(data=wordfreq.plot, aes(reorder(word, frequency), frequency)) + geom_bar(stat="identity") + coord_flip() + geom_text(aes(label=round(frequency, 2)), hjust=2, size=2, color="white") + fte_theme() + labs(y="Frequency", x="Words", title="Most frequent words")

```

# Remove some words 
```{r}
removewords <- c('acting','audience','back','care','come'
                 ,'dialogue','get','goes','making','minutes','movie'
                 ,'script','time','watch','thing', 'action','around'
                 ,'comes','first','gets','going','know','material'
                 ,'place','plays','plot','say','scenes','screenplay'
                 ,'things','think','watching', 'american','bit','can'
                 ,'character','director','film','find','give','gives'
                 ,'keep','kids','made','manages','may','something'
                 ,'sometimes','still','take','takes','two','war','way'
                 ,'will','without','women', 'actors','cast','films'
                 ,'makes','movies','one','piece','screen','see','seen'
                 ,'work','year','years')

new <- new[!new$word %chin% removewords]
```

# Prepare data to train model 
```{r}
wlist <- data.table(word=new$word, weight=new$bestSent)
# create a word id
wlist[, temp_ord := .I] # maybe you already have some order
wlist[, wid := paste0("w",sprintf("%04d",temp_ord))]
wlist[, temp_ord := NULL]
```


```{r, include=FALSE}
plist <- senTrain[, c("Phrase","SentenceId", "Sentiment")] 
setnames(plist,c("Phrase","SentenceId", "Sentiment"),c("phrase","phraseId", "sentiment"))
```

# Create phrase-word incidence (frequency) list
```{r}
plistw <- plist[, strsplit(phrase, ' '), by=list(phraseId, sentiment)] 
setnames(plistw, "V1", "word")
plistw <- plistw[, list(word_cnt=.N), by=list(phraseId, sentiment, word)]
```

# Match list words on the phrase
```{r}
plistw2 <- merge(plistw, wlist, by=c("word")) # inner join
plistw3 <- plistw2[,.(phraseId, sentiment, word_cnt, wid, weight)]
```

```{r}
plistw3 <- plistw3[,.(phraseId, sentiment, wid, weight)]
plistwide <- reshape(plistw3,idvar = c("phraseId", "sentiment"), timevar= "wid",direction = "wide" ,v.names = "weight")
```

```{r, include==FALSE}
tn <- names(plistwide)
#tn <- gsub("wcnt.","",tn, fixed= T)
tn <- gsub("weight.","",tn, fixed= T)
names(plistwide) <- tn
for(tcol in names(plistwide)){
  plistwide[is.na(get(tcol)), eval(tcol):=0]
}
```


# ==============
# Model Building
# ==============
# Do the same preparation on 30% data (test set)

```{r, include = FALSE}
plist.test <- senTest[, c("Phrase","SentenceId", "Sentiment")] 
setnames(plist.test,c("Phrase","SentenceId", "Sentiment"),c("phrase","phraseId", "sentiment"))
```
 

```{r, include = FALSE}
plistw.test <- plist.test[, strsplit(phrase, ' '), by=list(phraseId, sentiment)] 
setnames(plistw.test, "V1", "word")
plistw.test <- plistw.test[, list(word_cnt=.N), by=list(phraseId, sentiment, word)]
```

```{r, include = FALSE}
plistw.test2 <- merge(plistw.test, wlist, by=c("word"), all.y = TRUE) # inner join
length(which(is.na(plistw.test2)))
plistw.test3 <- plistw.test2[,.(phraseId, sentiment, word_cnt, wid, weight)]
length(which(is.na(plistw.test3)))
plistw.test3$phraseId[is.na(plistw.test3$phraseId)] <- 0
plistw.test3$sentiment[is.na(plistw.test3$sentiment)] <- 2
plistw.test3$word_cnt[is.na(plistw.test3$word_cnt)] <- 0
```

```{r, include = FALSE}
plistw.test3 <- plistw.test3[,.(phraseId, sentiment, wid, weight)]
plistwide.test <- reshape(plistw.test3,idvar = c("phraseId", "sentiment"), timevar= "wid",direction = "wide" ,v.names = "weight")
```



```{r, include = FALSE}
tn <- names(plistwide.test)
#tn <- gsub("wcnt.","",tn, fixed= T)
tn <- gsub("weight.","",tn, fixed= T)
names(plistwide.test) <- tn
for(tcol in names(plistwide.test)){
plistwide.test[is.na(get(tcol)), eval(tcol):=0]
  }
```
```{r, include = FALSE}
plistwide.test<- plistwide.test[!(plistwide.test$phraseId == 0),]
realSent <- plistwide.test[ , c("phraseId", "sentiment")] 
#take only sentiment label to compute confusion matrix
```



# Random forest



```{r}
plistwideRF <- rbind(plistwide, plistwide.test)
RFmodel <- randomForest(as.factor(sentiment) ~  .-phraseId , data = plistwideRF)
ptrainvalue <- predict(RFmodel, data=plistwideRF)
```

```{r}
m=as.matrix(table(ptrainvalue,as.factor(plistwideRF$sentiment)))
m
sum(diag(m)/sum(m))
```



# SVM (REGRESSION, OVE VS ALL APPROACH)

```{r, include = FALSE}
FN_setupLabel <- function(dtin, labelVar="sentiment", levelOne){
  # dtin <- bData
  # labelVar <- "label"
  # levelOne <- "2"
  dsin <- copy(dtin)
  dsin[get(labelVar) == levelOne, eval(labelVar):= -1]
  dsin[get(labelVar) >= 0, eval(labelVar) := 0]
  dsin[, eval(labelVar) := abs(get(labelVar))]
  # table(dsin[,labelVar, with = F])
  dsin
}

```

```{r}
FN_trainSVM <- function(dtin, outcomeVar = "sentiment"){
  prepFormula <- as.formula(paste0(outcomeVar," ~ . -phraseId"))
  model <- svm(prepFormula, data= dtin, type = "eps-regression")
  model
}

FN_train.bestSVM <- function(dtin, outcomeVar = "sentiment"){
  prepFormula <- as.formula(paste0(outcomeVar," ~ . -phraseId"))
  tuneResult <- tune(svm, prepFormula,  data = dtin,
                     ranges = list(epsilon = seq(0,0.2,0.01), cost = 2^(2:9)), scale = F) 
  tunedModel <- tuneResult$best.model
  tunedModel
}
```

```{r}
# Function evaluates its performance via the confusionMatrix for a given cutoff
FN_evalmodel <- function(tmodel, tsData, whichDigit = workOn, cutoff = 0.5){
  x <- predict(tmodel, tsData)
  x <- as.numeric(x > cutoff)
  y <- confusionMatrix(as.factor(x), as.factor(tsData[,sentiment]))
  y
}
```

```{r, include = FALSE}
#===============================================================================
#===============================================================================
# build SVR model  for each digit and store it and its best cutoff
#===============================================================================
#===============================================================================
BuildMySVM <- function(
  whichData = trainData 
  , workOn = 0 
  , testingData = keepData 
){
  #===============================================================================
  # Start working on sentiment recognition
  #===============================================================================
  
  set.seed(123)
  #===============================================================================
  # select a balanced sample of sentiment x and non sentiment x rows to train model
  #===============================================================================
  
  bData1 <- whichData[sentiment==workOn,] # take all rows with the sentiment worked on 
  
  # get 20% of each of the other digits' rows:
  bData2List <- lapply(c(0:4)[!c(0:4)%in%c(workOn)], function(x){
    # for each other sentiment, select first its rows
    tt <- whichData[sentiment==x,]
    # then get 20% of them...
    tsp <- sample(nrow(tt), floor(nrow(tt)/5), replace = F)
    # ... finally return those rows
    tt[tsp,]
  })
  
  bData2 <- rbindlist(bData2List) # stack the data tables with samples together
  table(bData2[,sentiment]) # confirm we got a decent representation of all other labels
  bData <- rbind(bData1, bData2) # stack the label and non-label rows
  rm(bData1, bData2, bData2List) # clean-up
  
  # setup outcome (label) to be 1 for the "workOn" sentiment, 0 otherwise
  bDataNew <- FN_setupLabel(bData, "sentiment", levelOne = workOn)
  table(bDataNew[,sentiment])
  bData <- copy(bDataNew); rm(bDataNew)
  
  # prepare the test data the same way
  testData <- FN_setupLabel(testingData, "sentiment", levelOne = workOn)
  
  #===============================================================================
  
  #===============================================================================
  # build SVM training function
  #===============================================================================
#model.svm <- FN_train.bestSVM(bData, outcomeVar = "sentiment")
  model.svm <- FN_trainSVM(bData, outcomeVar = "sentiment")

 
  #===============================================================================
  # evaluate the SVM over a grid to find the optimal cutoff
  #===============================================================================
  gridCutoff <- seq(from=0.01, to = 0.99, by=0.01)
  gridAccuracy <- lapply(gridCutoff, function(x) FN_evalmodel(tmodel = model.svm
                                                      , tsData = testData
                                                      , whichDigit = workOn
                                                      , cutoff = x)$overall["Accuracy"])
  
  # Identify the best cutoff
  SVM.bestCutoff <- gridCutoff[which.max(gridAccuracy)]
  # the next two rows are mostly useful in line-by-line debugging of the function, they do not return any data
  SVM.bestCutoff

  FN_evalmodel(model.svm, testData, cutoff = SVM.bestCutoff) # a bit better...
  
  # return a list containing the model and the best cutoff  
  return(list(model.svm, SVM.bestCutoff))
}
```

```{r, include= FALSE}
plistwide1 <- copy(plistwide)
plistwide1[, sentiment := as.numeric(sentiment)]


# train Boosting for each of the digits 0-9
system.time(
  SVMModelsList <- lapply(c(0:4), function(x) BuildMySVM(plistwide1, workOn=x, plistwide.test))
)

SVMAccuracy <- do.call(cbind, lapply(c(0:4), function(x) {
  keepDataTemp <- FN_setupLabel(plistwide.test, labelVar = "sentiment", levelOne = x)
  tempEval <- FN_evalmodel(SVMModelsList[[x+1]][[1]], keepDataTemp, x, SVMModelsList[[x+1]][[2]])
  print(tempEval$overall["Accuracy"])
}))

```

# Output of SVM Regression with the best cutoff 
```{r}
SVMAccuracy
```

```{r, include = FALSE}
predictSN <- predict(SVMModelsList[[1]][[1]], plistwide.test)
predictN <- predict(SVMModelsList[[2]][[1]], plistwide.test)
predictNE <- predict(SVMModelsList[[3]][[1]], plistwide.test)
predictP <- predict(SVMModelsList[[4]][[1]], plistwide.test)
predictSP <- predict(SVMModelsList[[5]][[1]], plistwide.test)

realSent <- cbind(realSent, predictSN, predictN, predictNE, predictP, predictSP)

realSent[, predictNE := as.numeric(predictNE > SVMModelsList[[3]][[2]])]
realSent[, predictP := as.numeric(predictP > SVMModelsList[[4]][[2]])]
realSent[, predictN := as.numeric(predictN > SVMModelsList[[2]][[2]])]
realSent[, predictSN := as.numeric(predictSN > SVMModelsList[[1]][[2]])]
realSent[, predictSP := as.numeric(predictSP > SVMModelsList[[5]][[2]])]
realSent$final[realSent$predictNE > 0]<- 2
realSent$final[realSent$predictP > 0]<- 3
realSent$final[realSent$predictN > 0]<- 1
realSent$final[realSent$predictSP > 0]<- 4
realSent$final[realSent$predictSN > 0 ]<- 0

for(tcol in names(realSent)){
  realSent[is.na(get(tcol)), eval(tcol):=2]
}
```
```{r}
confusionMatrix(as.factor(realSent$final), as.factor(realSent$sentiment))
```

# ========================
# SVM One vs one
# ========================

# Create a function to build model
```{r}
FN_trainSVMClass <- function(dtin, gamma = 1, cost = 1){
  # SVM
  datain <- copy(dtin)
  datain[, sentiment := as.factor(sentiment)]
  set.seed(2018)
  model <- svm(sentiment ~ . -phraseId, data= datain,
               kernel = "radial",
               gamma = 1, cost =1, scale = F)
  model
}
```

# Tried tune but Build a simple model with gamma = 1 and cost = 1
```{r}
FN_trainSVMBestClass <- function(dtin){
  # SVM
  datain <- copy(dtin)
  datain[, sentiment := as.factor(sentiment)]
  set.seed(2018)
  tune.out=tune(svm, sentiment ~ .-phraseId, data=datain, kernel ="radial",
                ranges =list(cost=c(0.1 ,1 ,10 ,100 ,1000),
                             gamma=c(0.5,1,2,3,4)))

  model.tuned = svm(sentiment ~ . -phraseId, data = datain
                    , kernel ="radial"
                    ,gamma = tune.out$best.parameters$gamma
                    , cost = tune.out$best.parameters$cost)
  model.tuned
}

```
# Create a function to test model 
```{r}
FN_evalmodelClass <- function(tmodel, datain) {
  tsData <- copy(datain)
  tsData[, sentiment := as.factor(sentiment)]
  x <- predict(tmodel, tsData, type="class")
  y <- confusionMatrix(x, tsData[,sentiment])
  y
}
```

# Run model 
```{r}
tmodel <- FN_trainSVMClass(plistwide)
# predict on train 
```
```{r}
SVMClass.result <- FN_evalmodelClass(tmodel,plistwide.test)
SVMClass.result
```

# 38.54% - the most reasonable so far 


