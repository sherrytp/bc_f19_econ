{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Become a pandas expert\n",
    "\n",
    "If you are looking to completely master the pandas library and become a trusted expert for doing data science work, check out my book [Master Data Analysis with Python][1]. It comes with over 300 exercises with detailed solutions covering the pandas library in-depth.\n",
    "\n",
    "[1]: https://www.dunderdata.com/master-data-analysis-with-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Optimize Custom Grouping Function\n",
    "In this challenge, your goal is to find the fastest solution to the problem while only using the Pandas library.\n",
    "\n",
    "### The Challenge\n",
    "The `college_pop` dataset contains the name, state and population of all higher-ed institutions in the US and its territories. For each state, find the percentage of the total state population made up by the 5 largest colleges of that state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama A &amp; M University</td>\n",
       "      <td>AL</td>\n",
       "      <td>4206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>University of Alabama at Birmingham</td>\n",
       "      <td>AL</td>\n",
       "      <td>11383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amridge University</td>\n",
       "      <td>AL</td>\n",
       "      <td>291.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>University of Alabama in Huntsville</td>\n",
       "      <td>AL</td>\n",
       "      <td>5451.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama State University</td>\n",
       "      <td>AL</td>\n",
       "      <td>4811.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name state      pop\n",
       "0             Alabama A & M University    AL   4206.0\n",
       "1  University of Alabama at Birmingham    AL  11383.0\n",
       "2                   Amridge University    AL    291.0\n",
       "3  University of Alabama in Huntsville    AL   5451.0\n",
       "4             Alabama State University    AL   4811.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "college = pd.read_csv('data/college_pop.csv')\n",
    "college.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>pop</th>\n",
       "      <th>pop_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama A &amp; M University</td>\n",
       "      <td>AL</td>\n",
       "      <td>4206.0</td>\n",
       "      <td>0.000260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>University of Alabama at Birmingham</td>\n",
       "      <td>AL</td>\n",
       "      <td>11383.0</td>\n",
       "      <td>0.000703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amridge University</td>\n",
       "      <td>AL</td>\n",
       "      <td>291.0</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>University of Alabama in Huntsville</td>\n",
       "      <td>AL</td>\n",
       "      <td>5451.0</td>\n",
       "      <td>0.000336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama State University</td>\n",
       "      <td>AL</td>\n",
       "      <td>4811.0</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name state      pop  pop_perc\n",
       "0             Alabama A & M University    AL   4206.0  0.000260\n",
       "1  University of Alabama at Birmingham    AL  11383.0  0.000703\n",
       "2                   Amridge University    AL    291.0  0.000018\n",
       "3  University of Alabama in Huntsville    AL   5451.0  0.000336\n",
       "4             Alabama State University    AL   4811.0  0.000297"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college['pop_perc'] = college['pop'] / college['pop'].sum()\n",
    "college.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Explain the 1,000x Speed Difference when taking the Mean\n",
    "In this challenge, your goal is to explain why taking the `mean` of the following DataFrame is more than 1,000 faster when using the parameter `numeric_only=True`.\n",
    "\n",
    "### The Challenge\n",
    "The `bikes` dataset below has about 50,000 rows. Taking the `mean` of the entire DataFrame returns the mean of all the numeric columns. If we set the parameter `numeric_only` to `True`, the exact same result is returned. But, using the second option results in a speed difference of more than 1,000x, taking the operation from over 40 seconds down to around 15 milliseconds.\n",
    "\n",
    "The challenge is to explain why there is a speed difference despite each of these operations returning the exact same result. The solution is fairly nuanced and requires a deep understanding of pandas. \n",
    "\n",
    "> My understanding is that the second method filters out the non-numerical columns first and then runs the mean operation, while the first method just runs the mean, so it takes more time for the system to opt out the posibility that some columns cannot be returned with mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>usertype</th>\n",
       "      <th>gender</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>from_station_name</th>\n",
       "      <th>latitude_start</th>\n",
       "      <th>longitude_start</th>\n",
       "      <th>dpcapacity_start</th>\n",
       "      <th>to_station_name</th>\n",
       "      <th>latitude_end</th>\n",
       "      <th>longitude_end</th>\n",
       "      <th>dpcapacity_end</th>\n",
       "      <th>temperature</th>\n",
       "      <th>visibility</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7147</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>2013-06-28 19:01:00</td>\n",
       "      <td>2013-06-28 19:17:00</td>\n",
       "      <td>993</td>\n",
       "      <td>Lake Shore Dr &amp; Monroe St</td>\n",
       "      <td>41.881050</td>\n",
       "      <td>-87.616970</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Michigan Ave &amp; Oak St</td>\n",
       "      <td>41.900960</td>\n",
       "      <td>-87.623777</td>\n",
       "      <td>15.0</td>\n",
       "      <td>73.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>mostlycloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7524</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>2013-06-28 22:53:00</td>\n",
       "      <td>2013-06-28 23:03:00</td>\n",
       "      <td>623</td>\n",
       "      <td>Clinton St &amp; Washington Blvd</td>\n",
       "      <td>41.883380</td>\n",
       "      <td>-87.641170</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Wells St &amp; Walton St</td>\n",
       "      <td>41.899930</td>\n",
       "      <td>-87.634430</td>\n",
       "      <td>19.0</td>\n",
       "      <td>69.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>partlycloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10927</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>2013-06-30 14:43:00</td>\n",
       "      <td>2013-06-30 15:01:00</td>\n",
       "      <td>1040</td>\n",
       "      <td>Sheffield Ave &amp; Kingsbury St</td>\n",
       "      <td>41.909592</td>\n",
       "      <td>-87.653497</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Dearborn St &amp; Monroe St</td>\n",
       "      <td>41.881320</td>\n",
       "      <td>-87.629521</td>\n",
       "      <td>23.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>mostlycloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12907</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>2013-07-01 10:05:00</td>\n",
       "      <td>2013-07-01 10:16:00</td>\n",
       "      <td>667</td>\n",
       "      <td>Carpenter St &amp; Huron St</td>\n",
       "      <td>41.894556</td>\n",
       "      <td>-87.653449</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Clark St &amp; Randolph St</td>\n",
       "      <td>41.884576</td>\n",
       "      <td>-87.631890</td>\n",
       "      <td>31.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>mostlycloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13168</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>2013-07-01 11:16:00</td>\n",
       "      <td>2013-07-01 11:18:00</td>\n",
       "      <td>130</td>\n",
       "      <td>Damen Ave &amp; Pierce Ave</td>\n",
       "      <td>41.909396</td>\n",
       "      <td>-87.677692</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Damen Ave &amp; Pierce Ave</td>\n",
       "      <td>41.909396</td>\n",
       "      <td>-87.677692</td>\n",
       "      <td>19.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>partlycloudy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trip_id    usertype gender            starttime             stoptime  \\\n",
       "0     7147  Subscriber   Male  2013-06-28 19:01:00  2013-06-28 19:17:00   \n",
       "1     7524  Subscriber   Male  2013-06-28 22:53:00  2013-06-28 23:03:00   \n",
       "2    10927  Subscriber   Male  2013-06-30 14:43:00  2013-06-30 15:01:00   \n",
       "3    12907  Subscriber   Male  2013-07-01 10:05:00  2013-07-01 10:16:00   \n",
       "4    13168  Subscriber   Male  2013-07-01 11:16:00  2013-07-01 11:18:00   \n",
       "\n",
       "   tripduration             from_station_name  latitude_start  \\\n",
       "0           993     Lake Shore Dr & Monroe St       41.881050   \n",
       "1           623  Clinton St & Washington Blvd       41.883380   \n",
       "2          1040  Sheffield Ave & Kingsbury St       41.909592   \n",
       "3           667       Carpenter St & Huron St       41.894556   \n",
       "4           130        Damen Ave & Pierce Ave       41.909396   \n",
       "\n",
       "   longitude_start  dpcapacity_start          to_station_name  latitude_end  \\\n",
       "0       -87.616970              11.0    Michigan Ave & Oak St     41.900960   \n",
       "1       -87.641170              31.0     Wells St & Walton St     41.899930   \n",
       "2       -87.653497              15.0  Dearborn St & Monroe St     41.881320   \n",
       "3       -87.653449              19.0   Clark St & Randolph St     41.884576   \n",
       "4       -87.677692              19.0   Damen Ave & Pierce Ave     41.909396   \n",
       "\n",
       "   longitude_end  dpcapacity_end  temperature  visibility  wind_speed  \\\n",
       "0     -87.623777            15.0         73.9        10.0        12.7   \n",
       "1     -87.634430            19.0         69.1        10.0         6.9   \n",
       "2     -87.629521            23.0         73.0        10.0        16.1   \n",
       "3     -87.631890            31.0         72.0        10.0        16.1   \n",
       "4     -87.677692            19.0         73.0        10.0        17.3   \n",
       "\n",
       "   precipitation        events  \n",
       "0        -9999.0  mostlycloudy  \n",
       "1        -9999.0  partlycloudy  \n",
       "2        -9999.0  mostlycloudy  \n",
       "3        -9999.0  mostlycloudy  \n",
       "4        -9999.0  partlycloudy  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes = pd.read_csv('data/bikes.csv')\n",
    "bikes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50089, 19)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trip_id             9.472308e+06\n",
       "tripduration        7.168678e+02\n",
       "latitude_start      4.190001e+01\n",
       "longitude_start    -8.764464e+01\n",
       "dpcapacity_start    2.134022e+01\n",
       "latitude_end        4.190058e+01\n",
       "longitude_end      -8.764485e+01\n",
       "dpcapacity_end      2.124171e+01\n",
       "temperature         6.260824e+01\n",
       "visibility          8.148827e+00\n",
       "wind_speed          7.070111e+00\n",
       "precipitation      -9.239627e+03\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 47s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 1 bikes.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.5 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 1 bikes.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Multiple Custom Grouping Aggregations\n",
    "\n",
    "This challenge is going to be fairly difficult, but should answer a question that many pandas users face - What is the best way to do a grouping operation that does many custom aggregations? In this context, a 'custom aggregation' is defined as one that is not directly available to use from pandas and one that you must write a custom function for. \n",
    "\n",
    "In Pandas Challenge 1, a single aggregation, which required a custom grouping function, was the desired result. In this challenge, you'll need to make several aggregations when grouping. There are a few different solutions to this problem, but depending on how you arrive at your solution, there could arise enormous performance differences. I am looking for a compact, readable solution with very good performance.\n",
    "\n",
    "### Sales Data\n",
    "\n",
    "In this challenge, you will be working with some mock sales data found in the sales.csv file. It contains 200,000 rows and 9 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>delivery_type</th>\n",
       "      <th>cost_type</th>\n",
       "      <th>duration</th>\n",
       "      <th>revenue</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13763</td>\n",
       "      <td>2019-03-25</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>F</td>\n",
       "      <td>slow</td>\n",
       "      <td>expert</td>\n",
       "      <td>60</td>\n",
       "      <td>553</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13673</td>\n",
       "      <td>2019-12-06</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>I</td>\n",
       "      <td>slow</td>\n",
       "      <td>experienced</td>\n",
       "      <td>60</td>\n",
       "      <td>895</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10287</td>\n",
       "      <td>2018-09-04</td>\n",
       "      <td>India</td>\n",
       "      <td>I</td>\n",
       "      <td>slow</td>\n",
       "      <td>novice</td>\n",
       "      <td>60</td>\n",
       "      <td>857</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14298</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>F</td>\n",
       "      <td>fastest</td>\n",
       "      <td>expert</td>\n",
       "      <td>120</td>\n",
       "      <td>741</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11523</td>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>Luxembourg</td>\n",
       "      <td>A</td>\n",
       "      <td>fast</td>\n",
       "      <td>expert</td>\n",
       "      <td>120</td>\n",
       "      <td>942</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id       date     country region delivery_type    cost_type  \\\n",
       "0        13763 2019-03-25    Portugal      F          slow       expert   \n",
       "1        13673 2019-12-06   Singapore      I          slow  experienced   \n",
       "2        10287 2018-09-04       India      I          slow       novice   \n",
       "3        14298 2018-06-21     Morocco      F       fastest       expert   \n",
       "4        11523 2019-01-05  Luxembourg      A          fast       expert   \n",
       "\n",
       "   duration  revenue  cost  \n",
       "0        60      553   295  \n",
       "1        60      895   262  \n",
       "2        60      857   260  \n",
       "3       120      741   238  \n",
       "4       120      942   263  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/sales.csv', parse_dates=['date'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "There are many aggregations that you will need to return and it will take some time to understand what they are and how to return them. The following definitions for two time periods will be used throughout the aggregations.\n",
    "\n",
    "Period **2019H1** is defined as the time period beginning January 1, 2019 and ending June 30, 2019.\n",
    "Period **2018H1** is defined as the time period beginning January 1, 2018 and ending June 30, 2018.\n",
    "\n",
    "### Aggregations\n",
    "Now, I will list all the aggregations that are expected to be returned. Each bullet point represents a single column. Use the first word after the bullet point as the new column name.\n",
    "\n",
    "For every country and region, return the following:\n",
    "* recency: Number of days between today's date (11/14/2019) and the maximum value of the 'date' column \n",
    "* fast_and_fastest: Number of unique customer_id in period 2019H1 with delivery_type either 'fast' or 'fastest'\n",
    "> Method 1: Using Boolean Variables; \n",
    "  Method 2: Using variable attributes\n",
    "* rev_2019: Total revenue for the period 2019H1\n",
    "* rev_2018: Total revenue for the period 2018H1\n",
    "* cost_2019: Total cost for period 2019H1\n",
    "* cost_2019_exp: Total cost for period 2019H1 with cost_type 'expert'\n",
    "* other_cost: Difference between cost_2019 and cost_2019_exp\n",
    "* **rev_per_60**: Total of revenue when duration equals 60 in period 2019H1 divided by number of unique customer_id when duration equals 60 in period 2019H1 \n",
    "* profit_margin: Take the difference of rev_2019 and cost_2019_exp then divide by rev_2019. Return as percentage\n",
    "* **cost_exp_per_60**: Total of cost when duration is 60 and cost_type is 'expert' in period 2019H1 divided by the number of unique customer_id when duration equals 60 and cost_type is 'expert' in period 2019H1 \n",
    "* growth: Find the percentage growth from revenue in period 2019H1 compared to the revenue in period 2018H1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-12-06 00:00:00')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('22 days 00:00:00')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recency = pd.to_datetime(\"2019-12-06\") - pd.to_datetime(\"2019-11-14\")\n",
    "recency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1716"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method 1: Using Boolean Variables\n",
    "H12019 = (pd.to_datetime(df['date']) > pd.to_datetime(\"2019-01-01\")) & (pd.to_datetime(df['date']) < pd.to_datetime(\"2019-06-30\"))\n",
    "fast = df['delivery_type'] == (\"fast\" or \"fastest\")\n",
    "fast_and_fastest = df[H12019 & fast]\n",
    "num = fast_and_fastest['customer_id'].unique()\n",
    "len(num)\n",
    "\n",
    "# Method 2: Using variable attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72023469"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_2019 = df[H12019]['revenue'].sum()\n",
    "rev_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47182081"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H12018 = (pd.to_datetime(df['date']) > pd.to_datetime(\"2018-01-01\")) & (pd.to_datetime(df['date']) < pd.to_datetime(\"2018-06-30\"))\n",
    "df[H12018]['revenue'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24097010"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_2019 = df[H12019]['cost'].sum()\n",
    "cost_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7985203"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert = df['cost_type'] == \"expert\"\n",
    "cost_2019_exp = df[H12019 & expert]['cost'].sum()\n",
    "cost_2019_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The other cost is $16111807\n"
     ]
    }
   ],
   "source": [
    "diff = df[H12019]['cost'].sum() - df[H12019 & expert]['cost'].sum()\n",
    "print(\"The other cost is $\" + str(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8228.956252863032"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rev_per_60: Total of revenue when duration equals 60 in period 2019H1 divided by number of unique customer_id when duration equals 60 in period 2019H1 \n",
    "duration = df['duration'] == 60\n",
    "df[duration & H12019]['revenue'].sum() / len(df[duration & H12019]['customer_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'88.9%'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:.1%}\".format((rev_2019 - cost_2019_exp) / rev_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1586.5744"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[duration & H12019 & expert]['cost'].sum() / len(df[duration & H12019 & expert]['customer_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.526500473770964"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rev_2019 - df[H12018]['revenue'].sum()) / (df[H12018]['revenue'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Finding the Date of the Largest Percentage Stock Price Drop \n",
    "\n",
    "In this challenge, you are given a table of closing stock prices for 10 different stocks with data going back as far as 1999. For each stock, find the date where it had its largest one-day percentage loss. The data is found in the `stocks10.csv` file with each stocks ticker symbol as a column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSFT</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>SLB</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>XOM</th>\n",
       "      <th>WMT</th>\n",
       "      <th>T</th>\n",
       "      <th>FB</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-10-25</th>\n",
       "      <td>29.84</td>\n",
       "      <td>2.32</td>\n",
       "      <td>17.02</td>\n",
       "      <td>82.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.45</td>\n",
       "      <td>38.99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-10-26</th>\n",
       "      <td>29.82</td>\n",
       "      <td>2.34</td>\n",
       "      <td>16.65</td>\n",
       "      <td>81.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.89</td>\n",
       "      <td>37.11</td>\n",
       "      <td>17.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-10-27</th>\n",
       "      <td>29.33</td>\n",
       "      <td>2.38</td>\n",
       "      <td>16.52</td>\n",
       "      <td>75.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.80</td>\n",
       "      <td>36.94</td>\n",
       "      <td>18.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-10-28</th>\n",
       "      <td>29.01</td>\n",
       "      <td>2.43</td>\n",
       "      <td>16.59</td>\n",
       "      <td>71.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.19</td>\n",
       "      <td>38.85</td>\n",
       "      <td>19.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-10-29</th>\n",
       "      <td>29.88</td>\n",
       "      <td>2.50</td>\n",
       "      <td>17.21</td>\n",
       "      <td>70.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.47</td>\n",
       "      <td>39.25</td>\n",
       "      <td>20.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MSFT  AAPL    SLB   AMZN  TSLA    XOM    WMT      T  FB   V\n",
       "date                                                                    \n",
       "1999-10-25  29.84  2.32  17.02  82.75   NaN  21.45  38.99  16.78 NaN NaN\n",
       "1999-10-26  29.82  2.34  16.65  81.25   NaN  20.89  37.11  17.28 NaN NaN\n",
       "1999-10-27  29.33  2.38  16.52  75.94   NaN  20.80  36.94  18.27 NaN NaN\n",
       "1999-10-28  29.01  2.43  16.59  71.00   NaN  21.19  38.85  19.79 NaN NaN\n",
       "1999-10-29  29.88  2.50  17.21  70.62   NaN  21.47  39.25  20.00 NaN NaN"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks = pd.read_csv('data/stocks10.csv', index_col='date', parse_dates=['date'])\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "There is a nice, fast solution that uses just a minimal amount of code without any loops. Can you return a Series that has the ticker symbols in the index and the date where the largest percentage price drop happened as the values. \n",
    "\n",
    "`pct_change`: the percentage change between the current value and the one immediately above it; $result = X_{t+1} - X$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSFT   2000-04-24\n",
       "AAPL   2000-09-29\n",
       "SLB    2008-10-15\n",
       "AMZN   2001-07-24\n",
       "TSLA   2012-01-13\n",
       "XOM    2008-10-15\n",
       "WMT    2018-02-20\n",
       "T      2000-12-19\n",
       "FB     2018-07-26\n",
       "V      2008-10-15\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks.pct_change().idxmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra challenge\n",
    "\n",
    "Can you return a DataFrame with the ticker symbol as the columns and a row for the date and another row for the percentage price drop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSFT</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>SLB</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>XOM</th>\n",
       "      <th>WMT</th>\n",
       "      <th>T</th>\n",
       "      <th>FB</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>idxmin</th>\n",
       "      <td>2000-04-24 00:00:00</td>\n",
       "      <td>2000-09-29 00:00:00</td>\n",
       "      <td>2008-10-15 00:00:00</td>\n",
       "      <td>2001-07-24 00:00:00</td>\n",
       "      <td>2012-01-13 00:00:00</td>\n",
       "      <td>2008-10-15 00:00:00</td>\n",
       "      <td>2018-02-20 00:00:00</td>\n",
       "      <td>2000-12-19 00:00:00</td>\n",
       "      <td>2018-07-26 00:00:00</td>\n",
       "      <td>2008-10-15 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.156201</td>\n",
       "      <td>-0.517964</td>\n",
       "      <td>-0.184057</td>\n",
       "      <td>-0.247661</td>\n",
       "      <td>-0.193274</td>\n",
       "      <td>-0.139395</td>\n",
       "      <td>-0.101816</td>\n",
       "      <td>-0.126392</td>\n",
       "      <td>-0.189609</td>\n",
       "      <td>-0.136295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       MSFT                 AAPL                  SLB  \\\n",
       "idxmin  2000-04-24 00:00:00  2000-09-29 00:00:00  2008-10-15 00:00:00   \n",
       "min               -0.156201            -0.517964            -0.184057   \n",
       "\n",
       "                       AMZN                 TSLA                  XOM  \\\n",
       "idxmin  2001-07-24 00:00:00  2012-01-13 00:00:00  2008-10-15 00:00:00   \n",
       "min               -0.247661            -0.193274            -0.139395   \n",
       "\n",
       "                        WMT                    T                   FB  \\\n",
       "idxmin  2018-02-20 00:00:00  2000-12-19 00:00:00  2018-07-26 00:00:00   \n",
       "min               -0.101816            -0.126392            -0.189609   \n",
       "\n",
       "                          V  \n",
       "idxmin  2008-10-15 00:00:00  \n",
       "min               -0.136295  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks.pct_change().agg(['idxmin', 'min'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Keeping Values Within Interquartile Range\n",
    "\n",
    "### Challenge\n",
    "For each stock, calculate the [interquartile range (IQR)][1]. Return a DataFrame that satisfies the following conditions:\n",
    "\n",
    "* Keep values as they are if they are within the IQR\n",
    "* For values lower than the first quartile, make them equal equal to the exact value of the first quartile\n",
    "* For values higher than the third quartile, make them equal equal to the exact value of the third quartile\n",
    "\n",
    "[1]: https://en.wikipedia.org/wiki/Interquartile_range\n",
    "\n",
    "There is a straightforward solution that completes this challenge in a single line of readable code. Can you find it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSFT</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>SLB</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>XOM</th>\n",
       "      <th>WMT</th>\n",
       "      <th>T</th>\n",
       "      <th>FB</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>19.15</td>\n",
       "      <td>3.91</td>\n",
       "      <td>25.62</td>\n",
       "      <td>40.46</td>\n",
       "      <td>33.9375</td>\n",
       "      <td>32.62</td>\n",
       "      <td>37.62</td>\n",
       "      <td>14.50</td>\n",
       "      <td>62.300</td>\n",
       "      <td>19.4750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>39.26</td>\n",
       "      <td>90.59</td>\n",
       "      <td>66.29</td>\n",
       "      <td>362.70</td>\n",
       "      <td>260.4700</td>\n",
       "      <td>71.81</td>\n",
       "      <td>65.15</td>\n",
       "      <td>26.23</td>\n",
       "      <td>162.305</td>\n",
       "      <td>80.3375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MSFT   AAPL    SLB    AMZN      TSLA    XOM    WMT      T       FB  \\\n",
       "0.25  19.15   3.91  25.62   40.46   33.9375  32.62  37.62  14.50   62.300   \n",
       "0.75  39.26  90.59  66.29  362.70  260.4700  71.81  65.15  26.23  162.305   \n",
       "\n",
       "            V  \n",
       "0.25  19.4750  \n",
       "0.75  80.3375  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks.quantile([.25, .75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "filter() got an unexpected keyword argument 'inclusive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-173fe1d26053>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# iqr = df['col'][df['col'].between(df['col'].quantile(.25), df['col'].quantile(.75), inclusive=True)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclusive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: filter() got an unexpected keyword argument 'inclusive'"
     ]
    }
   ],
   "source": [
    "# iqr = df['col'][df['col'].between(df['col'].quantile(.25), df['col'].quantile(.75), inclusive=True)]\n",
    "stocks.filter(stocks.quantile(.25), stocks.quantile(.75), inclusive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
