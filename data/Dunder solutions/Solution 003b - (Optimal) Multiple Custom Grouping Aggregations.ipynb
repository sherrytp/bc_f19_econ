{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dunder Data Challenge #3 Solution - (Optimal) - Multiple Custom Grouping Aggregations\n",
    "\n",
    "In this notebook, I will present an 'optimal' solution to challenge number 3. The original challenge description is re-posted below, followed by the naive and optimal solutions.\n",
    "\n",
    "## Master Python, Data Science and Machine Learning\n",
    "\n",
    "[Master the fundamentals of python, data science, and machine learning with my comprehensive and direct path to success.][0] There are over 500 exercises and projects with detailed solutions to help you become an expert.\n",
    "\n",
    "## Original Challenge\n",
    "\n",
    "This challenge is going to be fairly difficult, but should answer a question that many pandas users face - What is the best way to do a grouping operation that does many custom aggregations? In this context, a 'custom aggregation' is defined as one that is not directly available to use from pandas and one that you must write a custom function for. \n",
    "\n",
    "In Dunder Data Challenge 1, a single aggregation, which required a custom grouping function, was the desired result. In this challenge, you'll need to make several aggregations when grouping. There are a few different solutions to this problem, but depending on how you arrive at your solution, there could arise enormous performance differences. I am looking for a compact, readable solution with very good performance.\n",
    "\n",
    "### Sales Data\n",
    "\n",
    "In this challenge, you will be working with some mock sales data found in the sales.csv file. It contains 200,000 rows and 9 columns.\n",
    "\n",
    "[0]: https://www.dunderdata.com/store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>delivery_type</th>\n",
       "      <th>cost_type</th>\n",
       "      <th>duration</th>\n",
       "      <th>revenue</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>13763</td>\n",
       "      <td>2019-03-25</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>F</td>\n",
       "      <td>slow</td>\n",
       "      <td>expert</td>\n",
       "      <td>60</td>\n",
       "      <td>553</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>13673</td>\n",
       "      <td>2019-12-06</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>I</td>\n",
       "      <td>slow</td>\n",
       "      <td>experienced</td>\n",
       "      <td>60</td>\n",
       "      <td>895</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10287</td>\n",
       "      <td>2018-09-04</td>\n",
       "      <td>India</td>\n",
       "      <td>I</td>\n",
       "      <td>slow</td>\n",
       "      <td>novice</td>\n",
       "      <td>60</td>\n",
       "      <td>857</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>14298</td>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>F</td>\n",
       "      <td>fastest</td>\n",
       "      <td>expert</td>\n",
       "      <td>120</td>\n",
       "      <td>741</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11523</td>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>Luxembourg</td>\n",
       "      <td>A</td>\n",
       "      <td>fast</td>\n",
       "      <td>expert</td>\n",
       "      <td>120</td>\n",
       "      <td>942</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id       date     country region delivery_type    cost_type  \\\n",
       "0        13763 2019-03-25    Portugal      F          slow       expert   \n",
       "1        13673 2019-12-06   Singapore      I          slow  experienced   \n",
       "2        10287 2018-09-04       India      I          slow       novice   \n",
       "3        14298 2018-06-21     Morocco      F       fastest       expert   \n",
       "4        11523 2019-01-05  Luxembourg      A          fast       expert   \n",
       "\n",
       "   duration  revenue  cost  \n",
       "0        60      553   295  \n",
       "1        60      895   262  \n",
       "2        60      857   260  \n",
       "3       120      741   238  \n",
       "4       120      942   263  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/sales.csv', parse_dates=['date'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "There are many aggregations that you will need to return and it will take some time to understand what they are and how to return them. The following definitions for two time periods will be used throughout the aggregations.\n",
    "\n",
    "Period **2019H1** is defined as the time period beginning January 1, 2019 and ending June 30, 2019.\n",
    "Period **2018H1** is defined as the time period beginning January 1, 2018 and ending June 30, 2018.\n",
    "\n",
    "### Aggregations\n",
    "Now, I will list all the aggregations that are expected to be returned. Each bullet point represents a single column. Use the first word after the bullet point as the new column name.\n",
    "\n",
    "For every country and region, return the following:\n",
    "* recency: Number of days between today's date (9/9/2019) and the maximum value of the 'date' column \n",
    "* fast_and_fastest: Number of unique customer_id in period 2019H1 with delivery_type either 'fast' or 'fastest'\n",
    "* rev_2019: Total revenue for the period 2019H1\n",
    "* rev_2018: Total revenue for the period 2018H1\n",
    "* cost_2019: Total cost for period 2019H1\n",
    "* cost_2019_exp: Total cost for period 2019H1 with cost_type 'expert'\n",
    "* other_cost: Difference between cost_2019 and cost_2019_exp\n",
    "* rev_per_60: Total of revenue when duration equals 60 in period 2019H1 divided by number of unique customer_id when duration equals 60 in period 2019H1 \n",
    "* profit_margin: Take the difference of rev_2019 and cost_2019_exp then divide by rev_2019. Return as percentage\n",
    "* cost_exp_per_60: Total of cost when duration is 60 and cost_type is 'expert' in period 2019H1 divided by the number of unique customer_id when duration equals 60 and cost_type is 'expert' in period 2019H1 \n",
    "* growth: Find the percentage growth from revenue in period 2019H1 compared to the revenue in period 2018H1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Solution\n",
    "\n",
    "### Naive Solution - Custom function with apply\n",
    "\n",
    "The naive solution was presented in detail in the previous post. The end result is a massive custom function containing many boolean filters used to find specific subsets of data to aggregate. For each group, a Series was returned with 11 values. Each of these values became a new row in the resulting DataFrame. Let's take a look at the custom function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_final(x):\n",
    "    # filters\n",
    "    is_2019H1 =        x['date'].between('2019-01-01', '2019-06-30')\n",
    "    is_2018H1 =        x['date'].between('2018-01-01', '2018-06-30')\n",
    "    is_fast_fastest =  x['delivery_type'].isin({'fast', 'fastest'})\n",
    "    is_exp =           x['cost_type'] == 'expert'\n",
    "    is_60 =            x['duration'] == 60\n",
    "    is_2019H1_exp =    is_2019H1 & is_exp\n",
    "    is_2019H1_60 =     is_2019H1 & is_60\n",
    "    is_2019H1_60_exp = is_2019H1 & is_60 & is_exp\n",
    "    \n",
    "    # column calculations\n",
    "    recency =          (pd.Timestamp('today') - x['date'].max()).days\n",
    "    fast_and_fastest = x.loc[is_fast_fastest, 'customer_id'].nunique()\n",
    "    rev_2019 =         x.loc[is_2019H1, 'revenue'].sum()\n",
    "    rev_2018 =         x.loc[is_2018H1, 'revenue'].sum()\n",
    "    cost_2019 =        x.loc[is_2019H1, 'cost'].sum()\n",
    "    cost_2019_exp =    x.loc[is_2019H1_exp, 'cost'].sum()\n",
    "        \n",
    "    # helper calculations\n",
    "    rev_2019_60 =           x.loc[is_2019H1_60, 'revenue'].sum()\n",
    "    uniq_cust_2019_60 =     x.loc[is_2019H1_60, 'customer_id'].nunique()\n",
    "    cost_2019_exp_60 =      x.loc[is_2019H1_60_exp, 'cost'].sum()\n",
    "    uniq_cust_2019_exp_60 = x.loc[is_2019H1_60_exp, 'customer_id'].nunique()\n",
    "    \n",
    "    # more column calculations\n",
    "    other_cost =       cost_2019 - cost_2019_exp\n",
    "    rev_per_60 =       rev_2019_60 / uniq_cust_2019_60\n",
    "    profit_margin =    (rev_2019 - cost_2019_exp) / rev_2019 * 100\n",
    "    cost_exp_per_60 =  cost_2019_exp_60 / uniq_cust_2019_60\n",
    "    growth =           (rev_2019 - rev_2018) / rev_2018 * 100\n",
    "    \n",
    "    d = {\n",
    "        'recency': recency,\n",
    "        'fast_and_fastest': fast_and_fastest,\n",
    "        'rev_2019': rev_2019,\n",
    "        'rev_2018': rev_2018,\n",
    "        'cost_2019': cost_2019,\n",
    "        'cost_2019_exp': cost_2019_exp,\n",
    "        'other_cost': other_cost,\n",
    "        'rev_per_60': rev_per_60,\n",
    "        'profit_margin': profit_margin,\n",
    "        'cost_exp_per_60': cost_exp_per_60,\n",
    "        'growth': growth\n",
    "    }\n",
    "    \n",
    "    return pd.Series(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying this final function and formatting the resulting DataFrame yields the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68c\" ><thead>    <tr>        <th class=\"blank\" ></th>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >recency</th>        <th class=\"col_heading level0 col1\" >fast_and_fastest</th>        <th class=\"col_heading level0 col2\" >rev_2019</th>        <th class=\"col_heading level0 col3\" >rev_2018</th>        <th class=\"col_heading level0 col4\" >cost_2019</th>        <th class=\"col_heading level0 col5\" >cost_2019_exp</th>        <th class=\"col_heading level0 col6\" >other_cost</th>        <th class=\"col_heading level0 col7\" >rev_per_60</th>        <th class=\"col_heading level0 col8\" >profit_margin</th>        <th class=\"col_heading level0 col9\" >cost_exp_per_60</th>        <th class=\"col_heading level0 col10\" >growth</th>    </tr>    <tr>        <th class=\"index_name level0\" >country</th>        <th class=\"index_name level1\" >region</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68clevel0_row0\" class=\"row_heading level0 row0\" rowspan=5>Argentina</th>\n",
       "                        <th id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68clevel1_row0\" class=\"row_heading level1 row0\" >A</th>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow0_col0\" class=\"data row0 col0\" >-78</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow0_col1\" class=\"data row0 col1\" >138</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow0_col2\" class=\"data row0 col2\" >150,508</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow0_col3\" class=\"data row0 col3\" >82,912</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow0_col4\" class=\"data row0 col4\" >49,577</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow0_col5\" class=\"data row0 col5\" >18,553</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow0_col6\" class=\"data row0 col6\" >31,024</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow0_col7\" class=\"data row0 col7\" >773</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow0_col8\" class=\"data row0 col8\" >88</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow0_col9\" class=\"data row0 col9\" >111</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow0_col10\" class=\"data row0 col10\" >82</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68clevel1_row1\" class=\"row_heading level1 row1\" >B</th>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow1_col0\" class=\"data row1 col0\" >-80</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow1_col1\" class=\"data row1 col1\" >143</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow1_col2\" class=\"data row1 col2\" >139,048</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow1_col3\" class=\"data row1 col3\" >92,112</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow1_col4\" class=\"data row1 col4\" >46,153</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow1_col5\" class=\"data row1 col5\" >15,732</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow1_col6\" class=\"data row1 col6\" >30,421</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow1_col7\" class=\"data row1 col7\" >750</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow1_col8\" class=\"data row1 col8\" >89</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow1_col9\" class=\"data row1 col9\" >97</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow1_col10\" class=\"data row1 col10\" >51</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68clevel1_row2\" class=\"row_heading level1 row2\" >C</th>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow2_col0\" class=\"data row2 col0\" >-80</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow2_col1\" class=\"data row2 col1\" >129</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow2_col2\" class=\"data row2 col2\" >118,035</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow2_col3\" class=\"data row2 col3\" >98,472</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow2_col4\" class=\"data row2 col4\" >38,786</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow2_col5\" class=\"data row2 col5\" >12,661</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow2_col6\" class=\"data row2 col6\" >26,125</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow2_col7\" class=\"data row2 col7\" >780</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow2_col8\" class=\"data row2 col8\" >89</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow2_col9\" class=\"data row2 col9\" >105</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow2_col10\" class=\"data row2 col10\" >20</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68clevel1_row3\" class=\"row_heading level1 row3\" >D</th>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow3_col0\" class=\"data row3 col0\" >-80</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow3_col1\" class=\"data row3 col1\" >135</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow3_col2\" class=\"data row3 col2\" >131,728</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow3_col3\" class=\"data row3 col3\" >79,600</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow3_col4\" class=\"data row3 col4\" >44,190</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow3_col5\" class=\"data row3 col5\" >17,217</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow3_col6\" class=\"data row3 col6\" >26,973</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow3_col7\" class=\"data row3 col7\" >730</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow3_col8\" class=\"data row3 col8\" >87</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow3_col9\" class=\"data row3 col9\" >88</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow3_col10\" class=\"data row3 col10\" >65</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68clevel1_row4\" class=\"row_heading level1 row4\" >E</th>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow4_col0\" class=\"data row4 col0\" >-80</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow4_col1\" class=\"data row4 col1\" >177</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow4_col2\" class=\"data row4 col2\" >146,201</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow4_col3\" class=\"data row4 col3\" >93,119</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow4_col4\" class=\"data row4 col4\" >49,600</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow4_col5\" class=\"data row4 col5\" >18,372</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow4_col6\" class=\"data row4 col6\" >31,228</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow4_col7\" class=\"data row4 col7\" >747</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow4_col8\" class=\"data row4 col8\" >87</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow4_col9\" class=\"data row4 col9\" >110</td>\n",
       "                        <td id=\"T_86fe7d02_d990_11e9_bbbd_b8e85647e68crow4_col10\" class=\"data row4 col10\" >57</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x102d402e8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.groupby(['country', 'region']).apply(f_final)\n",
    "df1.head().style.format('{:,.0f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our performance with this final function is more than 3.5 seconds. While this is a lot less than 8 hours, the calculations we performed in the custom function were fairly simple and our data was just 200k rows. If the data and complexity of the custom function increases by an 1-2 order of magnitudes each, hours of computation time await."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.92 s ± 199 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit df.groupby(['country', 'region']).apply(f_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Solution\n",
    "\n",
    "In order to greatly increase our performance, we need to take advantage of the **built-in** methods available to groupby objects. Above, we used a custom function to do many, many calculations. These calculations were performed on each group. Let's get the total number of groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "520"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.groupby(['country', 'region']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of these 520 groups, the massive `f_final` function was called, recomputing each filter. Running these same calculations for each group is one of the main causes of poor performance with `apply`.\n",
    "\n",
    "Take a look at all the filters in `f_final`. You'll notice that each of them are independent on the particular group. This means that we can calculate these filters **before** grouping and get the same result. As a concrete example, take a look at the following DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>category</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>TX</td>\n",
       "      <td>tech</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>energy</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>TX</td>\n",
       "      <td>energy</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CA</td>\n",
       "      <td>tech</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>CA</td>\n",
       "      <td>energy</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>CA</td>\n",
       "      <td>energy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state category  revenue\n",
       "0    TX     tech       10\n",
       "1    TX   energy        5\n",
       "2    TX   energy        8\n",
       "3    CA     tech       20\n",
       "4    CA   energy       12\n",
       "5    CA   energy        2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rev = pd.DataFrame({'state': ['TX', 'TX', 'TX', 'CA', 'CA', 'CA'], \n",
    "                       'category': ['tech', 'energy', 'energy', 'tech', 'energy', 'energy'],\n",
    "                       'revenue' : [10, 5, 8, 20, 12, 2]})\n",
    "df_rev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the revenue for each state, but just for the energy category. A naive solution involves writing a custom function, where each group will be filtered for just the energy category and then have the revenue summed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    is_energy = x['category'] == 'energy'\n",
    "    return x.loc[is_energy, 'revenue'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this custom function with apply returns the correct revenue for each state's energy category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "CA    14\n",
       "TX    13\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rev.groupby('state').apply(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we can create an entire new column for just the energy revenue. First, we create a boolean Series where `True` corresponds to 'energy'. We multiply this Series by the original revenue column. Because `False` evaluates to 0 and `True` evaluates as 1, the new column will be just like the original, but have the 0 everywhere the category is not energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>category</th>\n",
       "      <th>revenue</th>\n",
       "      <th>energy_revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>TX</td>\n",
       "      <td>tech</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>energy</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>TX</td>\n",
       "      <td>energy</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CA</td>\n",
       "      <td>tech</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>CA</td>\n",
       "      <td>energy</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>CA</td>\n",
       "      <td>energy</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state category  revenue  energy_revenue\n",
       "0    TX     tech       10               0\n",
       "1    TX   energy        5               5\n",
       "2    TX   energy        8               8\n",
       "3    CA     tech       20               0\n",
       "4    CA   energy       12              12\n",
       "5    CA   energy        2               2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = df_rev['category'] == 'energy'\n",
    "df_rev['energy_revenue'] = filt * df_rev['revenue']\n",
    "df_rev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the built-in `sum` method instead of our custom function during the grouping. There is no need for `apply` here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "CA    14\n",
       "TX    13\n",
       "Name: energy_revenue, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rev.groupby('state')['energy_revenue'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the `where` method\n",
    "Instead of replacing the filtered values with 0, as we did above, you might need to make them missing. This is crucial if you are calculating something like the mean or median, which will take into account the value of 0. The `where` method will replace the `False` values of the passed boolean Series with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>category</th>\n",
       "      <th>revenue</th>\n",
       "      <th>energy_revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>TX</td>\n",
       "      <td>tech</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>energy</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>TX</td>\n",
       "      <td>energy</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CA</td>\n",
       "      <td>tech</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>CA</td>\n",
       "      <td>energy</td>\n",
       "      <td>12</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>CA</td>\n",
       "      <td>energy</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state category  revenue  energy_revenue\n",
       "0    TX     tech       10             NaN\n",
       "1    TX   energy        5             5.0\n",
       "2    TX   energy        8             8.0\n",
       "3    CA     tech       20             NaN\n",
       "4    CA   energy       12            12.0\n",
       "5    CA   energy        2             2.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = df_rev['category'] == 'energy'\n",
    "df_rev['energy_revenue'] = df_rev['revenue'].where(filt)\n",
    "df_rev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call the same groupby to get the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "CA    14.0\n",
       "TX    13.0\n",
       "Name: energy_revenue, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rev.groupby('state')['energy_revenue'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter with our challenge data\n",
    "Let's calculate `rev_2019` which is defined as the revenue during the first half of 2019. Let's use the naive way of thinking first by defining a custom function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rev_2019(x):\n",
    "    is_2019H1 = x['date'].between('2019-01-01', '2019-06-30')\n",
    "    return x.loc[is_2019H1, 'revenue'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country    region\n",
       "Argentina  A         150508\n",
       "           B         139048\n",
       "           C         118035\n",
       "           D         131728\n",
       "           E         146201\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['country', 'region']).apply(get_rev_2019).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use our new method of applying the filter to the entire DataFrame first, creating a new column, and then using the built-in `sum` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country    region\n",
       "Argentina  A         150508.0\n",
       "           B         139048.0\n",
       "           C         118035.0\n",
       "           D         131728.0\n",
       "           E         146201.0\n",
       "Name: rev_2019, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_2019H1 = df['date'].between('2019-01-01', '2019-06-30')\n",
    "df['rev_2019'] =  df['revenue'].where(is_2019H1)\n",
    "df.groupby(['country', 'region'])['rev_2019'].sum().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom function vs built-in method performance comparison\n",
    "Let's compare the performance between the two methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633 ms ± 15.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit df.groupby(['country', 'region']).apply(get_rev_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.3 ms ± 530 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "is_2019H1 = df['date'].between('2019-01-01', '2019-06-30')\n",
    "df['rev_2019'] = df['revenue'].where(is_2019H1)\n",
    "df.groupby(['country', 'region'])['rev_2019'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom function is 25x slower than the built-in method and this is just a simple calculation. The more complex the custom function, the larger the performance difference becomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The trick to avoiding apply\n",
    "\n",
    "If you are attempting to avoid using apply, then you have no choice but to use the built-in groupby methods. This limits the possibilities and forces you to approach the problem differently. The main 'trick' is to execute operations to the entire DataFrame before using the groupby method. \n",
    "\n",
    "Not all operations will be able to be executed on the entire DataFrame, only those that are **independent** of the group. So, how do you know if an operation is independent of the group? The operation will not have calculation that is specific to the current group. For instance, we are grouping by country and region. If an operation is dependent on the particular country or region, then it would not be able to be executed on the entire DataFrame. \n",
    "\n",
    "A concrete example can help here - If the definition of the first half of the year was January through July for Greece and January through June for all other countries, then the calculation of revenue for the first half of the year would depend on the group.\n",
    "\n",
    "In this challenge, all the operations are independent of the group. There are no special cases based on the group. This means that we can execute all of our operations that we used within the custom function passed to `apply` outside of it before we group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete optimal solution\n",
    "\n",
    "The complete optimal solution will now be given. We will use the same definition for our filters as we did in the custom function, but instead calculate them on the entire DataFrame. We will then create new columns that have NaN where the filters is `False`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cost</th>\n",
       "      <th>rev_2019</th>\n",
       "      <th>rev_2018</th>\n",
       "      <th>fast_and_fastest</th>\n",
       "      <th>cost_2019</th>\n",
       "      <th>cost_2019_exp</th>\n",
       "      <th>rev_2019_60</th>\n",
       "      <th>uniq_cust_2019_60</th>\n",
       "      <th>cost_2019_exp_60</th>\n",
       "      <th>uniq_cust_2019_exp_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>295</td>\n",
       "      <td>553.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>295.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>553.0</td>\n",
       "      <td>13763.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>13763.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>741.0</td>\n",
       "      <td>14298.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>263</td>\n",
       "      <td>942.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11523.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cost  rev_2019  rev_2018  fast_and_fastest  cost_2019  cost_2019_exp  \\\n",
       "0   295     553.0       NaN               NaN      295.0          295.0   \n",
       "1   262       NaN       NaN               NaN        NaN            NaN   \n",
       "2   260       NaN       NaN               NaN        NaN            NaN   \n",
       "3   238       NaN     741.0           14298.0        NaN            NaN   \n",
       "4   263     942.0       NaN           11523.0      263.0          263.0   \n",
       "\n",
       "   rev_2019_60  uniq_cust_2019_60  cost_2019_exp_60  uniq_cust_2019_exp_60  \n",
       "0        553.0            13763.0             295.0                13763.0  \n",
       "1          NaN                NaN               NaN                    NaN  \n",
       "2          NaN                NaN               NaN                    NaN  \n",
       "3          NaN                NaN               NaN                    NaN  \n",
       "4          NaN                NaN               NaN                    NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df.copy()\n",
    "# filters\n",
    "is_2019H1 =        df_new['date'].between('2019-01-01', '2019-06-30')\n",
    "is_2018H1 =        df_new['date'].between('2018-01-01', '2018-06-30')\n",
    "is_fast_fastest =  df_new['delivery_type'].isin({'fast', 'fastest'})\n",
    "is_exp =           df_new['cost_type'] == 'expert'\n",
    "is_60 =            df_new['duration'] == 60\n",
    "is_2019H1_exp =    is_2019H1 & is_exp\n",
    "is_2019H1_60 =     is_2019H1 & is_60\n",
    "is_2019H1_60_exp = is_2019H1 & is_60 & is_exp\n",
    "\n",
    "# new columns\n",
    "df_new['rev_2019'] =              df_new['revenue'].where(is_2019H1)\n",
    "df_new['rev_2018'] =              df_new['revenue'].where(is_2018H1)\n",
    "df_new['fast_and_fastest'] =      df_new['customer_id'].where(is_fast_fastest)\n",
    "df_new['cost_2019'] =             df_new['cost'].where(is_2019H1)\n",
    "df_new['cost_2019_exp'] =         df_new['cost'].where(is_2019H1_exp)\n",
    "df_new['rev_2019_60'] =           df_new['revenue'].where(is_2019H1_60)\n",
    "df_new['uniq_cust_2019_60'] =     df_new['customer_id'].where(is_2019H1_60)\n",
    "df_new['cost_2019_exp_60'] =      df_new['cost'].where(is_2019H1_60_exp)\n",
    "df_new['uniq_cust_2019_exp_60'] = df_new['customer_id'].where(is_2019H1_60_exp)\n",
    "\n",
    "df_new.iloc[:5, -10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use just the built-in groupby methods to aggregate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>recency</th>\n",
       "      <th>fast_and_fastest</th>\n",
       "      <th>rev_2019</th>\n",
       "      <th>rev_2018</th>\n",
       "      <th>cost_2019</th>\n",
       "      <th>cost_2019_exp</th>\n",
       "      <th>rev_2019_60</th>\n",
       "      <th>uniq_cust_2019_60</th>\n",
       "      <th>cost_2019_exp_60</th>\n",
       "      <th>uniq_cust_2019_exp_60</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">Argentina</td>\n",
       "      <td>A</td>\n",
       "      <td>2019-12-04</td>\n",
       "      <td>138</td>\n",
       "      <td>150508.0</td>\n",
       "      <td>82912.0</td>\n",
       "      <td>49577.0</td>\n",
       "      <td>18553.0</td>\n",
       "      <td>71106.0</td>\n",
       "      <td>92</td>\n",
       "      <td>10215.0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>B</td>\n",
       "      <td>2019-12-06</td>\n",
       "      <td>143</td>\n",
       "      <td>139048.0</td>\n",
       "      <td>92112.0</td>\n",
       "      <td>46153.0</td>\n",
       "      <td>15732.0</td>\n",
       "      <td>67471.0</td>\n",
       "      <td>90</td>\n",
       "      <td>8694.0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C</td>\n",
       "      <td>2019-12-06</td>\n",
       "      <td>129</td>\n",
       "      <td>118035.0</td>\n",
       "      <td>98472.0</td>\n",
       "      <td>38786.0</td>\n",
       "      <td>12661.0</td>\n",
       "      <td>57721.0</td>\n",
       "      <td>74</td>\n",
       "      <td>7747.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D</td>\n",
       "      <td>2019-12-06</td>\n",
       "      <td>135</td>\n",
       "      <td>131728.0</td>\n",
       "      <td>79600.0</td>\n",
       "      <td>44190.0</td>\n",
       "      <td>17217.0</td>\n",
       "      <td>60629.0</td>\n",
       "      <td>83</td>\n",
       "      <td>7284.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>E</td>\n",
       "      <td>2019-12-06</td>\n",
       "      <td>177</td>\n",
       "      <td>146201.0</td>\n",
       "      <td>93119.0</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>18372.0</td>\n",
       "      <td>73223.0</td>\n",
       "      <td>98</td>\n",
       "      <td>10772.0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    recency  fast_and_fastest  rev_2019  rev_2018  cost_2019  \\\n",
       "country   region                                                               \n",
       "Argentina A      2019-12-04               138  150508.0   82912.0    49577.0   \n",
       "          B      2019-12-06               143  139048.0   92112.0    46153.0   \n",
       "          C      2019-12-06               129  118035.0   98472.0    38786.0   \n",
       "          D      2019-12-06               135  131728.0   79600.0    44190.0   \n",
       "          E      2019-12-06               177  146201.0   93119.0    49600.0   \n",
       "\n",
       "                  cost_2019_exp  rev_2019_60  uniq_cust_2019_60  \\\n",
       "country   region                                                  \n",
       "Argentina A             18553.0      71106.0                 92   \n",
       "          B             15732.0      67471.0                 90   \n",
       "          C             12661.0      57721.0                 74   \n",
       "          D             17217.0      60629.0                 83   \n",
       "          E             18372.0      73223.0                 98   \n",
       "\n",
       "                  cost_2019_exp_60  uniq_cust_2019_exp_60  \n",
       "country   region                                           \n",
       "Argentina A                10215.0                     41  \n",
       "          B                 8694.0                     36  \n",
       "          C                 7747.0                     32  \n",
       "          D                 7284.0                     30  \n",
       "          E                10772.0                     43  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new1 = \\\n",
    "    df_new.groupby(['country', 'region']).agg(\n",
    "       recency =               ('date', 'max'),\n",
    "       fast_and_fastest =      ('fast_and_fastest', 'nunique'),\n",
    "       rev_2019 =              ('rev_2019', 'sum'),\n",
    "       rev_2018 =              ('rev_2018', 'sum'),\n",
    "       cost_2019 =             ('cost_2019', 'sum'),\n",
    "       cost_2019_exp =         ('cost_2019_exp', 'sum'),\n",
    "       rev_2019_60 =           ('rev_2019_60', 'sum'),\n",
    "       uniq_cust_2019_60 =     ('uniq_cust_2019_60', 'nunique'),\n",
    "       cost_2019_exp_60 =      ('cost_2019_exp_60', 'sum'),\n",
    "       uniq_cust_2019_exp_60 = ('uniq_cust_2019_exp_60', 'nunique'))\n",
    "\n",
    "df_new1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not the final DataFrame, as some columns can only be calculated from the result of the aggregated values. We also need to drop some of these intermediate columns that are no longer desired in the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>recency</th>\n",
       "      <th>fast_and_fastest</th>\n",
       "      <th>rev_2019</th>\n",
       "      <th>rev_2018</th>\n",
       "      <th>cost_2019</th>\n",
       "      <th>cost_2019_exp</th>\n",
       "      <th>other_cost</th>\n",
       "      <th>rev_per_60</th>\n",
       "      <th>profit_margin</th>\n",
       "      <th>cost_exp_per_60</th>\n",
       "      <th>growth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">Argentina</td>\n",
       "      <td>A</td>\n",
       "      <td>-78</td>\n",
       "      <td>138</td>\n",
       "      <td>150508.0</td>\n",
       "      <td>82912.0</td>\n",
       "      <td>49577.0</td>\n",
       "      <td>18553.0</td>\n",
       "      <td>31024.0</td>\n",
       "      <td>772.891304</td>\n",
       "      <td>87.673081</td>\n",
       "      <td>111.032609</td>\n",
       "      <td>81.527403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>B</td>\n",
       "      <td>-80</td>\n",
       "      <td>143</td>\n",
       "      <td>139048.0</td>\n",
       "      <td>92112.0</td>\n",
       "      <td>46153.0</td>\n",
       "      <td>15732.0</td>\n",
       "      <td>30421.0</td>\n",
       "      <td>749.677778</td>\n",
       "      <td>88.685921</td>\n",
       "      <td>96.600000</td>\n",
       "      <td>50.955359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C</td>\n",
       "      <td>-80</td>\n",
       "      <td>129</td>\n",
       "      <td>118035.0</td>\n",
       "      <td>98472.0</td>\n",
       "      <td>38786.0</td>\n",
       "      <td>12661.0</td>\n",
       "      <td>26125.0</td>\n",
       "      <td>780.013514</td>\n",
       "      <td>89.273521</td>\n",
       "      <td>104.689189</td>\n",
       "      <td>19.866561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D</td>\n",
       "      <td>-80</td>\n",
       "      <td>135</td>\n",
       "      <td>131728.0</td>\n",
       "      <td>79600.0</td>\n",
       "      <td>44190.0</td>\n",
       "      <td>17217.0</td>\n",
       "      <td>26973.0</td>\n",
       "      <td>730.469880</td>\n",
       "      <td>86.929886</td>\n",
       "      <td>87.759036</td>\n",
       "      <td>65.487437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>E</td>\n",
       "      <td>-80</td>\n",
       "      <td>177</td>\n",
       "      <td>146201.0</td>\n",
       "      <td>93119.0</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>18372.0</td>\n",
       "      <td>31228.0</td>\n",
       "      <td>747.173469</td>\n",
       "      <td>87.433738</td>\n",
       "      <td>109.918367</td>\n",
       "      <td>57.004478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  recency  fast_and_fastest  rev_2019  rev_2018  cost_2019  \\\n",
       "country   region                                                             \n",
       "Argentina A           -78               138  150508.0   82912.0    49577.0   \n",
       "          B           -80               143  139048.0   92112.0    46153.0   \n",
       "          C           -80               129  118035.0   98472.0    38786.0   \n",
       "          D           -80               135  131728.0   79600.0    44190.0   \n",
       "          E           -80               177  146201.0   93119.0    49600.0   \n",
       "\n",
       "                  cost_2019_exp  other_cost  rev_per_60  profit_margin  \\\n",
       "country   region                                                         \n",
       "Argentina A             18553.0     31024.0  772.891304      87.673081   \n",
       "          B             15732.0     30421.0  749.677778      88.685921   \n",
       "          C             12661.0     26125.0  780.013514      89.273521   \n",
       "          D             17217.0     26973.0  730.469880      86.929886   \n",
       "          E             18372.0     31228.0  747.173469      87.433738   \n",
       "\n",
       "                  cost_exp_per_60     growth  \n",
       "country   region                              \n",
       "Argentina A            111.032609  81.527403  \n",
       "          B             96.600000  50.955359  \n",
       "          C            104.689189  19.866561  \n",
       "          D             87.759036  65.487437  \n",
       "          E            109.918367  57.004478  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new1['recency'] =          (pd.Timestamp('now') - df_new1['recency']).dt.days\n",
    "df_new1['other_cost'] =       df_new1['cost_2019'] - df_new1['cost_2019_exp']\n",
    "df_new1['rev_per_60'] =       df_new1['rev_2019_60'] / df_new1['uniq_cust_2019_60']\n",
    "df_new1['profit_margin'] =    (df_new1['rev_2019'] - df_new1['cost_2019_exp']) / df_new1['rev_2019'] * 100\n",
    "df_new1['cost_exp_per_60'] =  df_new1['cost_2019_exp_60'] / df_new1['uniq_cust_2019_60']\n",
    "df_new1['growth'] =           (df_new1['rev_2019'] - df_new1['rev_2018']) / df_new1['rev_2018'] * 100\n",
    "df_new1 = df_new1.drop(columns=['uniq_cust_2019_60', 'uniq_cust_2019_exp_60', 'rev_2019_60', 'cost_2019_exp_60'])\n",
    "df_new1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520, 11)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that the DataFrames are equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.groupby(['country', 'region']).apply(f_final)\n",
    "df1.equals(df_new1.astype('float'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put all the steps of the optimal solution into a single function, which we can then use to measure performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal():\n",
    "    df_new = df.copy()\n",
    "    \n",
    "    # filters\n",
    "    is_2019H1 =        df_new['date'].between('2019-01-01', '2019-06-30')\n",
    "    is_2018H1 =        df_new['date'].between('2018-01-01', '2018-06-30')\n",
    "    is_fast_fastest =  df_new['delivery_type'].isin({'fast', 'fastest'})\n",
    "    is_exp =           df_new['cost_type'] == 'expert'\n",
    "    is_60 =            df_new['duration'] == 60\n",
    "    is_2019H1_exp =    is_2019H1 & is_exp\n",
    "    is_2019H1_60 =     is_2019H1 & is_60\n",
    "    is_2019H1_60_exp = is_2019H1 & is_60 & is_exp\n",
    "\n",
    "    # new columns\n",
    "    df_new['rev_2019'] =              df_new['revenue'].where(is_2019H1)\n",
    "    df_new['rev_2018'] =              df_new['revenue'].where(is_2018H1)\n",
    "    df_new['fast_and_fastest'] =      df_new['customer_id'].where(is_fast_fastest)\n",
    "    df_new['cost_2019'] =             df_new['cost'].where(is_2019H1)\n",
    "    df_new['cost_2019_exp'] =         df_new['cost'].where(is_2019H1_exp)\n",
    "    df_new['rev_2019_60'] =           df_new['revenue'].where(is_2019H1_60)\n",
    "    df_new['uniq_cust_2019_60'] =     df_new['customer_id'].where(is_2019H1_60)\n",
    "    df_new['cost_2019_exp_60'] =      df_new['cost'].where(is_2019H1_60_exp)\n",
    "    df_new['uniq_cust_2019_exp_60'] = df_new['customer_id'].where(is_2019H1_60_exp)\n",
    "\n",
    "    # built-in aggregations\n",
    "    df_new1 = \\\n",
    "        df_new.groupby(['country', 'region']).agg(\n",
    "           recency =               ('date', 'max'),\n",
    "           fast_and_fastest =      ('fast_and_fastest', 'nunique'),\n",
    "           rev_2019 =              ('rev_2019', 'sum'),\n",
    "           rev_2018 =              ('rev_2018', 'sum'),\n",
    "           cost_2019 =             ('cost_2019', 'sum'),\n",
    "           cost_2019_exp =         ('cost_2019_exp', 'sum'),\n",
    "           rev_2019_60 =           ('rev_2019_60', 'sum'),\n",
    "           uniq_cust_2019_60 =     ('uniq_cust_2019_60', 'nunique'),\n",
    "           cost_2019_exp_60 =      ('cost_2019_exp_60', 'sum'),\n",
    "           uniq_cust_2019_exp_60 = ('uniq_cust_2019_exp_60', 'nunique'))\n",
    "    \n",
    "    df_new1['recency'] =          (pd.Timestamp('now') - df_new1['recency']).dt.days\n",
    "    df_new1['other_cost'] =       df_new1['cost_2019'] - df_new1['cost_2019_exp']\n",
    "    df_new1['rev_per_60'] =       df_new1['rev_2019_60'] / df_new1['uniq_cust_2019_60']\n",
    "    df_new1['profit_margin'] =    (df_new1['rev_2019'] - df_new1['cost_2019_exp']) / df_new1['rev_2019'] * 100\n",
    "    df_new1['cost_exp_per_60'] =  df_new1['cost_2019_exp_60'] / df_new1['uniq_cust_2019_60']\n",
    "    df_new1['growth'] =           (df_new1['rev_2019'] - df_new1['rev_2018']) / df_new1['rev_2018'] * 100\n",
    "    \n",
    "    # drop columns not needed in final result\n",
    "    df_new1 = df_new1.drop(columns=['uniq_cust_2019_60', 'uniq_cust_2019_exp_60', \n",
    "                                    'rev_2019_60', 'cost_2019_exp_60'])\n",
    "    return df_new1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About 20x faster\n",
    "\n",
    "The optimal solution is about 20x as fast as the naive solution due to precalculating new columns and only using built-in groupby methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201 ms ± 2.48 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit optimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Become a pandas expert\n",
    "\n",
    "If you are looking to completely master the pandas library and become a trusted expert for doing data science work, check out my book [Master Data Analysis with Python][1]. It comes with over 300 exercises with detailed solutions covering the pandas library in-depth.\n",
    "\n",
    "[1]: https://www.dunderdata.com/master-data-analysis-with-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
